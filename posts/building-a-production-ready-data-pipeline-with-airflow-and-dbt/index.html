<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="prefer-datetime-locale" content="de"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="Building a Production-Ready Data Pipeline with Airflow and dbt" /><meta property="og:locale" content="en" /><meta name="description" content="A comprehensive walkthrough of implementing a modern sales data engineering pipeline with Airflow, dbt, and PostgreSQL, focusing on practical insights and real-world patterns." /><meta property="og:description" content="A comprehensive walkthrough of implementing a modern sales data engineering pipeline with Airflow, dbt, and PostgreSQL, focusing on practical insights and real-world patterns." /><link rel="canonical" href="https://samueltyh.github.io/posts/building-a-production-ready-data-pipeline-with-airflow-and-dbt/" /><meta property="og:url" content="https://samueltyh.github.io/posts/building-a-production-ready-data-pipeline-with-airflow-and-dbt/" /><meta property="og:site_name" content="samueltyh" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2025-04-28T14:30:00+02:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Building a Production-Ready Data Pipeline with Airflow and dbt" /><meta name="twitter:site" content="@samueltyh" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-04-28T15:58:57+02:00","datePublished":"2025-04-28T14:30:00+02:00","description":"A comprehensive walkthrough of implementing a modern sales data engineering pipeline with Airflow, dbt, and PostgreSQL, focusing on practical insights and real-world patterns.","headline":"Building a Production-Ready Data Pipeline with Airflow and dbt","mainEntityOfPage":{"@type":"WebPage","@id":"https://samueltyh.github.io/posts/building-a-production-ready-data-pipeline-with-airflow-and-dbt/"},"url":"https://samueltyh.github.io/posts/building-a-production-ready-data-pipeline-with-airflow-and-dbt/"}</script><title>Building a Production-Ready Data Pipeline with Airflow and dbt | samueltyh</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="samueltyh"><meta name="application-name" content="samueltyh"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> <img src="/assets/img/AvatarMaker.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">samueltyh</a></div><div class="site-subtitle font-italic">DevOps, Data Engineering, Data Science</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/samueltyh" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/samueltyh" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['samueltseng','icloud.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Building a Production-Ready Data Pipeline with Airflow and dbt</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Building a Production-Ready Data Pipeline with Airflow and dbt</h1><div class="post-meta text-muted"> <span> Posted <em class="" data-ts="1745843400" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Apr 28, 2025 </em> </span> <span> Updated <em class="" data-ts="1745848737" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Apr 28, 2025 </em> </span><div class="d-flex justify-content-between"> <span> By <em> <a href="https://twitter.com/samueltyh">Samuel Tseng</a> </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="3129 words"> <em>17 min</em> read</span></div></div></div><div class="post-content"><p>In today’s data-driven business landscape, transforming raw operational data into actionable insights requires robust, scalable data pipelines. I recently designed and implemented a comprehensive data engineering solution for sales analytics that bridges raw transactional data to dimensional models. This post walks through the architecture, implementation decisions, and practical patterns that you can apply to your own data engineering projects.</p><h2 id="the-challenge-from-sales-transactions-to-analytics"><span class="mr-2">The Challenge: From Sales Transactions to Analytics</span><a href="#the-challenge-from-sales-transactions-to-analytics" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>The core challenge was to build a pipeline that would:</p><ol><li>Ingest sales transaction data from multiple CSV sources<li>Handle common data quality issues (missing values, inconsistent formats)<li>Transform raw data into a dimensional model for analytics<li>Implement incremental processing for efficiency<li>Ensure reliability with comprehensive testing and error handling</ol><h2 id="architecture-design-medallion-pattern-implementation"><span class="mr-2">Architecture Design: Medallion Pattern Implementation</span><a href="#architecture-design-medallion-pattern-implementation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>After evaluating several architectural approaches, I implemented a medallion architecture (also called multi-hop architecture), which organizes data through progressive refinement stages:</p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>Raw CSV Data → Bronze Layer (raw.sales) → Silver Layer (transformed.dim_*) → Gold Layer (analytics.fact_sales)
</pre></table></code></div></div><p>This layered approach provides several key advantages:</p><ul><li>Clear separation of concerns<li>Progressive data quality improvement<li>Complete data lineage traceability<li>Flexibility to rebuild downstream layers without re-ingesting source data</ul><h3 id="database-schema-design"><span class="mr-2">Database Schema Design</span><a href="#database-schema-design" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>I designed the following schema structure:</p><ul><li><strong>Bronze Layer</strong>: Raw data storage with original values preserved<ul><li><code class="language-plaintext highlighter-rouge">raw.sales</code>: Original CSV data with added metadata columns</ul><li><strong>Silver Layer</strong>: Cleaned and transformed dimensional models<ul><li><code class="language-plaintext highlighter-rouge">transformed.dim_product</code>: Product information<li><code class="language-plaintext highlighter-rouge">transformed.dim_retailer</code>: Retailer information<li><code class="language-plaintext highlighter-rouge">transformed.dim_location</code>: Location information<li><code class="language-plaintext highlighter-rouge">transformed.dim_channel</code>: Sales channel information<li><code class="language-plaintext highlighter-rouge">transformed.dim_date</code>: Date dimension with hierarchies<li><code class="language-plaintext highlighter-rouge">transformed.fact_sales</code>: Sales fact table with foreign keys and measures</ul><li><strong>Gold Layer</strong>: Analytics-ready views and aggregates<ul><li><code class="language-plaintext highlighter-rouge">analytics.dim_*</code>: Analytics-ready dimension views<li><code class="language-plaintext highlighter-rouge">analytics.fact_sales</code>: Optimized analytical fact table</ul></ul><h2 id="implementation-core-components"><span class="mr-2">Implementation: Core Components</span><a href="#implementation-core-components" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h3 id="1-data-ingestion-module"><span class="mr-2">1. Data Ingestion Module</span><a href="#1-data-ingestion-module" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>The ingestion component follows a “validate-first, then clean” pattern, which provides better visibility into data quality issues:</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="n">file_path</span><span class="p">):</span>
    <span class="s">"""
    Main function to process and load data.
    New flow: Validate first, then clean only records that need cleaning.
    """</span>
    <span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s">"Starting data ingestion process for </span><span class="si">{</span><span class="n">file_path</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Read the CSV file
</span>        <span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s">"Reading file: </span><span class="si">{</span><span class="n">file_path</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>
        <span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s">"Successfully read </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="si">}</span><span class="s"> records from </span><span class="si">{</span><span class="n">file_path</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
        
        <span class="c1"># First validate the data as-is
</span>        <span class="n">is_valid</span><span class="p">,</span> <span class="n">invalid_indices</span> <span class="o">=</span> <span class="n">validate_data</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_valid</span><span class="p">:</span>
            <span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="s">"Data validation failed. Applying cleaning steps..."</span><span class="p">)</span>
            <span class="c1"># Apply cleaning only after validation fails
</span>            <span class="n">df</span> <span class="o">=</span> <span class="n">CleanData</span><span class="p">.</span><span class="n">apply_all_cleaners</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
            
            <span class="c1"># Re-validate after cleaning
</span>            <span class="n">is_valid</span><span class="p">,</span> <span class="n">invalid_indices</span> <span class="o">=</span> <span class="n">validate_data</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">is_valid</span><span class="p">:</span>
                <span class="n">logger</span><span class="p">.</span><span class="n">warning</span><span class="p">(</span><span class="s">"Data still contains invalid records after cleaning. Filtering them out."</span><span class="p">)</span>
                <span class="n">df</span> <span class="o">=</span> <span class="n">filter_invalid_records</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">invalid_indices</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="s">"Data cleaning resolved all validation issues."</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="s">"Data passed validation without cleaning."</span><span class="p">)</span>
        
        <span class="c1"># Check for duplicates
</span>        <span class="n">deduplicated_df</span> <span class="o">=</span> <span class="n">detect_duplicates</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
        
        <span class="c1"># Only proceed with loading if we have records
</span>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">deduplicated_df</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Get database connection string
</span>            <span class="n">connection_string</span> <span class="o">=</span> <span class="n">get_db_connection_string</span><span class="p">()</span>
            
            <span class="c1"># Load to raw schema
</span>            <span class="n">records_loaded</span> <span class="o">=</span> <span class="n">load_to_raw</span><span class="p">(</span><span class="n">deduplicated_df</span><span class="p">,</span> <span class="n">connection_string</span><span class="p">,</span> <span class="n">file_path</span><span class="p">)</span>
            
            <span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s">"Data ingestion complete. </span><span class="si">{</span><span class="n">records_loaded</span><span class="si">}</span><span class="s"> records processed."</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">records_loaded</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="p">.</span><span class="n">warning</span><span class="p">(</span><span class="s">"No valid records to load after validation and deduplication."</span><span class="p">)</span>
            <span class="k">return</span> <span class="mi">0</span>
        
    <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="p">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s">"Error in data ingestion process: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
        <span class="k">raise</span>
</pre></table></code></div></div><p>I encapsulated the cleaning operations in a dedicated class with specialized methods for each type of cleaning:</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
</pre><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">CleanData</span><span class="p">:</span>
    <span class="s">"""
    A class for handling different types of data cleaning operations.
    Each method handles a specific type of cleaning.
    """</span>
    
    <span class="o">@</span><span class="nb">staticmethod</span>
    <span class="k">def</span> <span class="nf">handle_missing_values</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
        <span class="s">"""Handle missing values in the DataFrame."""</span>
        <span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="s">"Cleaning: Handling missing values..."</span><span class="p">)</span>
        <span class="n">df_cleaned</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">df_cleaned</span><span class="p">[</span><span class="s">'Location'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_cleaned</span><span class="p">[</span><span class="s">'Location'</span><span class="p">].</span><span class="n">fillna</span><span class="p">(</span><span class="s">'Unknown'</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">df_cleaned</span>
    
    <span class="o">@</span><span class="nb">staticmethod</span>
    <span class="k">def</span> <span class="nf">clean_price_values</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
        <span class="s">"""Clean price values by removing currency symbols."""</span>
        <span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="s">"Cleaning: Cleaning price values..."</span><span class="p">)</span>
        <span class="n">df_cleaned</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
        
        <span class="c1"># Handle price with currency notation
</span>        <span class="n">df_cleaned</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df_cleaned</span><span class="p">[</span><span class="s">'Price'</span><span class="p">].</span><span class="nb">str</span><span class="p">.</span><span class="n">contains</span><span class="p">(</span><span class="s">'USD'</span><span class="p">,</span> <span class="n">na</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span> <span class="s">'Price'</span><span class="p">]</span> <span class="o">=</span> \
            <span class="n">df_cleaned</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df_cleaned</span><span class="p">[</span><span class="s">'Price'</span><span class="p">].</span><span class="nb">str</span><span class="p">.</span><span class="n">contains</span><span class="p">(</span><span class="s">'USD'</span><span class="p">,</span> <span class="n">na</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span> <span class="s">'Price'</span><span class="p">].</span><span class="nb">str</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="s">'USD'</span><span class="p">,</span> <span class="s">''</span><span class="p">)</span>
        
        <span class="c1"># Strip whitespace
</span>        <span class="n">df_cleaned</span><span class="p">[</span><span class="s">'Price'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_cleaned</span><span class="p">[</span><span class="s">'Price'</span><span class="p">].</span><span class="nb">str</span><span class="p">.</span><span class="n">strip</span><span class="p">()</span>
        
        <span class="k">return</span> <span class="n">df_cleaned</span>
    
    <span class="c1"># More cleaning methods...
</span>    
    <span class="o">@</span><span class="nb">classmethod</span>
    <span class="k">def</span> <span class="nf">apply_all_cleaners</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">df</span><span class="p">):</span>
        <span class="s">"""Apply all cleaning methods in sequence."""</span>
        <span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="s">"Starting comprehensive data cleaning..."</span><span class="p">)</span>
        
        <span class="n">df_result</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">df_result</span> <span class="o">=</span> <span class="n">cls</span><span class="p">.</span><span class="n">handle_missing_values</span><span class="p">(</span><span class="n">df_result</span><span class="p">)</span>
        <span class="n">df_result</span> <span class="o">=</span> <span class="n">cls</span><span class="p">.</span><span class="n">standardize_data_types</span><span class="p">(</span><span class="n">df_result</span><span class="p">)</span>
        <span class="n">df_result</span> <span class="o">=</span> <span class="n">cls</span><span class="p">.</span><span class="n">remove_whitespace_values</span><span class="p">(</span><span class="n">df_result</span><span class="p">)</span>
        <span class="n">df_result</span> <span class="o">=</span> <span class="n">cls</span><span class="p">.</span><span class="n">clean_price_values</span><span class="p">(</span><span class="n">df_result</span><span class="p">)</span>
        <span class="n">df_result</span> <span class="o">=</span> <span class="n">cls</span><span class="p">.</span><span class="n">clean_date_values</span><span class="p">(</span><span class="n">df_result</span><span class="p">)</span>
        
        <span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s">"Comprehensive data cleaning complete. Processed </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">df_result</span><span class="p">)</span><span class="si">}</span><span class="s"> rows."</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">df_result</span>
</pre></table></code></div></div><h3 id="2-data-transformation-layer"><span class="mr-2">2. Data Transformation Layer</span><a href="#2-data-transformation-layer" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>After landing raw data, the transformation component converts it into a proper dimensional model:</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">process_sales_data</span><span class="p">(</span><span class="n">engine</span><span class="p">):</span>
    <span class="s">"""
    Process and transform sales data from raw to fact table.
    """</span>
    
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Get dimension lookups
</span>        <span class="n">channel_ids</span> <span class="o">=</span> <span class="n">populate_dim_channel</span><span class="p">(</span><span class="n">engine</span><span class="p">)</span>
        <span class="n">location_ids</span> <span class="o">=</span> <span class="n">populate_dim_location</span><span class="p">(</span><span class="n">engine</span><span class="p">)</span>
        <span class="n">product_ids</span> <span class="o">=</span> <span class="n">populate_dim_product</span><span class="p">(</span><span class="n">engine</span><span class="p">)</span>
        <span class="n">retailer_ids</span> <span class="o">=</span> <span class="n">populate_dim_retailer</span><span class="p">(</span><span class="n">engine</span><span class="p">)</span>
        <span class="n">date_ids</span> <span class="o">=</span> <span class="n">populate_dim_date</span><span class="p">(</span><span class="n">engine</span><span class="p">)</span>
        
        <span class="c1"># Query to get raw sales data
</span>        <span class="n">query</span> <span class="o">=</span> <span class="s">"""
        SELECT "SaleID", "ProductID", "RetailerID", "Channel", "Location", 
               "Quantity", "Price", "Date"
        FROM raw.sales
        WHERE "SaleID" NOT IN (
            SELECT sale_id::VARCHAR FROM transformed.fact_sales
        )
        ORDER BY "SaleID" ASC
        """</span>
        
        <span class="k">with</span> <span class="n">engine</span><span class="p">.</span><span class="n">begin</span><span class="p">()</span> <span class="k">as</span> <span class="n">conn</span><span class="p">:</span>
            <span class="c1"># Count total records to process
</span>            <span class="n">count_query</span> <span class="o">=</span> <span class="s">"""
            SELECT COUNT(*) FROM raw.sales
            WHERE "SaleID" NOT IN (
                SELECT sale_id::VARCHAR FROM transformed.fact_sales
            )
            """</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">conn</span><span class="p">.</span><span class="n">execute</span><span class="p">(</span><span class="n">text</span><span class="p">(</span><span class="n">count_query</span><span class="p">))</span>
            <span class="n">total_records</span> <span class="o">=</span> <span class="n">result</span><span class="p">.</span><span class="n">fetchone</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s">"Found </span><span class="si">{</span><span class="n">total_records</span><span class="si">}</span><span class="s"> new sales records to process"</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="n">total_records</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="s">"No new records to process"</span><span class="p">)</span>
                <span class="k">return</span> <span class="mi">0</span>
            
            <span class="n">result</span> <span class="o">=</span> <span class="n">conn</span><span class="p">.</span><span class="n">execute</span><span class="p">(</span><span class="n">text</span><span class="p">(</span><span class="n">query</span><span class="p">))</span>
            <span class="n">sales</span> <span class="o">=</span> <span class="p">[</span><span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">row</span><span class="p">))</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">result</span><span class="p">]</span>
            
            <span class="c1"># Transform data
</span>            <span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s">"Processing </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">sales</span><span class="p">)</span><span class="si">}</span><span class="s"> sales records"</span><span class="p">)</span>
            <span class="n">processed_count</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">fact_records</span> <span class="o">=</span> <span class="p">[]</span>
            
            <span class="c1"># Process each sale record
</span>            <span class="k">for</span> <span class="n">sale</span> <span class="ow">in</span> <span class="n">sales</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="c1"># Data transformations here...
</span>                    
                    <span class="c1"># Create fact record
</span>                    <span class="n">fact_record</span> <span class="o">=</span> <span class="p">{</span>
                        <span class="s">"sale_id"</span><span class="p">:</span> <span class="n">sale_id</span><span class="p">,</span>
                        <span class="s">"product_id"</span><span class="p">:</span> <span class="n">product_id</span><span class="p">,</span>
                        <span class="s">"retailer_id"</span><span class="p">:</span> <span class="n">retailer_id</span><span class="p">,</span>
                        <span class="s">"location_id"</span><span class="p">:</span> <span class="n">location_id</span><span class="p">,</span>
                        <span class="s">"channel_id"</span><span class="p">:</span> <span class="n">channel_id</span><span class="p">,</span>
                        <span class="s">"date_id"</span><span class="p">:</span> <span class="n">date_id</span><span class="p">,</span>
                        <span class="s">"quantity"</span><span class="p">:</span> <span class="n">quantity</span><span class="p">,</span>
                        <span class="s">"unit_price"</span><span class="p">:</span> <span class="n">unit_price</span><span class="p">,</span>
                        <span class="s">"total_amount"</span><span class="p">:</span> <span class="n">total_amount</span>
                    <span class="p">}</span>
                    <span class="n">fact_records</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">fact_record</span><span class="p">)</span>
                <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">logger</span><span class="p">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s">"Error processing sale </span><span class="si">{</span><span class="n">sale</span><span class="p">[</span><span class="s">'SaleID'</span><span class="p">]</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
            
            <span class="c1"># Insert fact records
</span>            <span class="k">if</span> <span class="n">fact_records</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">insert_query</span> <span class="o">=</span> <span class="s">"""
                    INSERT INTO transformed.fact_sales (
                        sale_id, product_id, retailer_id, location_id, 
                        channel_id, date_id, quantity, unit_price, total_amount
                    )
                    VALUES (
                        :sale_id, :product_id, :retailer_id, :location_id, 
                        :channel_id, :date_id, :quantity, :unit_price, :total_amount
                    )
                    ON CONFLICT (sale_id) DO NOTHING
                    """</span>
                    <span class="c1"># Use a new transaction to ensure atomicity
</span>                    <span class="k">with</span> <span class="n">engine</span><span class="p">.</span><span class="n">begin</span><span class="p">()</span> <span class="k">as</span> <span class="n">insert_conn</span><span class="p">:</span>
                        <span class="n">insert_conn</span><span class="p">.</span><span class="n">execute</span><span class="p">(</span><span class="n">text</span><span class="p">(</span><span class="n">insert_query</span><span class="p">),</span> <span class="n">fact_records</span><span class="p">)</span>
                    
                    <span class="n">processed_count</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">fact_records</span><span class="p">)</span>
                    <span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s">"Inserted </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">fact_records</span><span class="p">)</span><span class="si">}</span><span class="s"> records into fact_sales"</span><span class="p">)</span>
                <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">logger</span><span class="p">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s">"Error inserting: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
            
            <span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s">"Successfully processed </span><span class="si">{</span><span class="n">processed_count</span><span class="si">}</span><span class="s"> sales records"</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">processed_count</span>
    <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="p">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s">"Error processing sales data: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
        <span class="k">raise</span>
</pre></table></code></div></div><h3 id="3-dbt-transformation-models"><span class="mr-2">3. dbt Transformation Models</span><a href="#3-dbt-transformation-models" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>For the analytical layer, I implemented dbt models that further refine the data:</p><p>First, a staging model to standardize raw data formats:</p><div class="language-sql highlighter-rouge"><div class="code-header"> <span data-label-text="Sql"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
</pre><td class="rouge-code"><pre><span class="c1">-- stg_sales.sql</span>

<span class="k">with</span> <span class="k">source</span> <span class="k">as</span> <span class="p">(</span>
    <span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="p">{{</span> <span class="k">source</span><span class="p">(</span><span class="s1">'postgres'</span><span class="p">,</span> <span class="s1">'sales'</span><span class="p">)</span> <span class="p">}}</span>
<span class="p">),</span>

<span class="n">cleaned</span> <span class="k">as</span> <span class="p">(</span>
    <span class="k">select</span>
        <span class="nv">"SaleID"</span><span class="p">::</span><span class="nb">integer</span> <span class="k">as</span> <span class="n">sale_id</span><span class="p">,</span>
        <span class="k">nullif</span><span class="p">(</span><span class="nv">"ProductID"</span><span class="p">,</span> <span class="s1">''</span><span class="p">)::</span><span class="nb">integer</span> <span class="k">as</span> <span class="n">product_id</span><span class="p">,</span>
        <span class="nv">"ProductName"</span> <span class="k">as</span> <span class="n">product_name</span><span class="p">,</span>
        <span class="nv">"Brand"</span> <span class="k">as</span> <span class="n">brand</span><span class="p">,</span>
        <span class="nv">"Category"</span> <span class="k">as</span> <span class="n">category</span><span class="p">,</span>
        <span class="nv">"RetailerID"</span><span class="p">::</span><span class="nb">integer</span> <span class="k">as</span> <span class="n">retailer_id</span><span class="p">,</span>
        <span class="nv">"RetailerName"</span> <span class="k">as</span> <span class="n">retailer_name</span><span class="p">,</span>
        <span class="nv">"Channel"</span> <span class="k">as</span> <span class="n">channel</span><span class="p">,</span>
        <span class="n">coalesce</span><span class="p">(</span><span class="k">nullif</span><span class="p">(</span><span class="nv">"Location"</span><span class="p">,</span> <span class="s1">''</span><span class="p">),</span> <span class="s1">'Unknown'</span><span class="p">)</span> <span class="k">as</span> <span class="k">location</span><span class="p">,</span>
        <span class="k">case</span> 
            <span class="k">when</span> <span class="nv">"Quantity"</span> <span class="o">~</span> <span class="s1">'^-?</span><span class="se">\d</span><span class="s1">+$'</span> <span class="k">then</span> <span class="nv">"Quantity"</span><span class="p">::</span><span class="nb">integer</span>
            <span class="k">else</span> <span class="k">null</span>
        <span class="k">end</span> <span class="k">as</span> <span class="n">quantity</span><span class="p">,</span>
        <span class="k">case</span>
            <span class="k">when</span> <span class="nv">"Price"</span> <span class="o">~</span> <span class="s1">'^</span><span class="se">\d</span><span class="s1">+$'</span> <span class="k">then</span> <span class="nv">"Price"</span><span class="p">::</span><span class="nb">decimal</span>
            <span class="k">when</span> <span class="nv">"Price"</span> <span class="o">~</span> <span class="s1">'^</span><span class="se">\d</span><span class="s1">+USD$'</span> <span class="k">then</span> <span class="k">replace</span><span class="p">(</span><span class="nv">"Price"</span><span class="p">,</span> <span class="s1">'USD'</span><span class="p">,</span> <span class="s1">''</span><span class="p">)::</span><span class="nb">decimal</span>
            <span class="k">else</span> <span class="k">null</span>
        <span class="k">end</span> <span class="k">as</span> <span class="n">price</span><span class="p">,</span>
        <span class="k">case</span>
            <span class="k">when</span> <span class="nv">"Date"</span> <span class="o">~</span> <span class="s1">'^</span><span class="se">\d</span><span class="s1">{4}-</span><span class="se">\d</span><span class="s1">{2}-</span><span class="se">\d</span><span class="s1">{2}$'</span> <span class="k">then</span> <span class="nv">"Date"</span><span class="p">::</span><span class="nb">date</span>
            <span class="k">when</span> <span class="nv">"Date"</span> <span class="o">~</span> <span class="s1">'^</span><span class="se">\d</span><span class="s1">{4}/</span><span class="se">\d</span><span class="s1">{2}/</span><span class="se">\d</span><span class="s1">{2}$'</span> <span class="k">then</span> <span class="n">to_date</span><span class="p">(</span><span class="nv">"Date"</span><span class="p">,</span> <span class="s1">'YYYY/MM/DD'</span><span class="p">)</span>
            <span class="k">else</span> <span class="k">null</span>
        <span class="k">end</span> <span class="k">as</span> <span class="nb">date</span><span class="p">,</span>
        <span class="n">batch_id</span><span class="p">,</span>
        <span class="n">source_file</span><span class="p">,</span>
        <span class="n">inserted_at</span>
    <span class="k">from</span> <span class="k">source</span>
<span class="p">),</span>

<span class="k">final</span> <span class="k">as</span> <span class="p">(</span>
    <span class="k">select</span>
        <span class="n">sale_id</span><span class="p">,</span>
        <span class="n">product_id</span><span class="p">,</span>
        <span class="n">product_name</span><span class="p">,</span>
        <span class="n">brand</span><span class="p">,</span>
        <span class="n">category</span><span class="p">,</span>
        <span class="n">retailer_id</span><span class="p">,</span>
        <span class="n">retailer_name</span><span class="p">,</span>
        <span class="n">channel</span><span class="p">,</span>
        <span class="k">location</span><span class="p">,</span>
        <span class="k">case</span> <span class="k">when</span> <span class="n">quantity</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="k">then</span> <span class="k">null</span> <span class="k">else</span> <span class="n">quantity</span> <span class="k">end</span> <span class="k">as</span> <span class="n">quantity</span><span class="p">,</span>
        <span class="n">price</span><span class="p">,</span>
        <span class="nb">date</span><span class="p">,</span>
        <span class="n">batch_id</span><span class="p">,</span>
        <span class="n">source_file</span><span class="p">,</span>
        <span class="n">inserted_at</span><span class="p">,</span>
        <span class="k">current_timestamp</span> <span class="k">as</span> <span class="n">transformed_at</span>
    <span class="k">from</span> <span class="n">cleaned</span>
    <span class="k">where</span> 
        <span class="n">sale_id</span> <span class="k">is</span> <span class="k">not</span> <span class="k">null</span>
        <span class="k">and</span> <span class="n">product_id</span> <span class="k">is</span> <span class="k">not</span> <span class="k">null</span>
        <span class="k">and</span> <span class="n">retailer_id</span> <span class="k">is</span> <span class="k">not</span> <span class="k">null</span>
        <span class="k">and</span> <span class="nb">date</span> <span class="k">is</span> <span class="k">not</span> <span class="k">null</span>
        <span class="k">and</span> <span class="n">quantity</span> <span class="k">is</span> <span class="k">not</span> <span class="k">null</span>
        <span class="k">and</span> <span class="n">price</span> <span class="k">is</span> <span class="k">not</span> <span class="k">null</span>
<span class="p">)</span>

<span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="k">final</span>
</pre></table></code></div></div><p>Then dimensional models built on top of staging:</p><div class="language-sql highlighter-rouge"><div class="code-header"> <span data-label-text="Sql"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
</pre><td class="rouge-code"><pre><span class="c1">-- fact_sales.sql</span>

<span class="p">{{</span>
  <span class="n">config</span><span class="p">(</span>
    <span class="n">unique_key</span> <span class="o">=</span> <span class="s1">'sale_id'</span><span class="p">,</span>
    <span class="n">indexes</span> <span class="o">=</span> <span class="p">[</span>
      <span class="p">{</span><span class="s1">'columns'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'sale_id'</span><span class="p">],</span> <span class="s1">'unique'</span><span class="p">:</span> <span class="k">True</span><span class="p">},</span>
      <span class="p">{</span><span class="s1">'columns'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'product_id'</span><span class="p">]},</span>
      <span class="p">{</span><span class="s1">'columns'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'retailer_id'</span><span class="p">]},</span>
      <span class="p">{</span><span class="s1">'columns'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'location_id'</span><span class="p">]},</span>
      <span class="p">{</span><span class="s1">'columns'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'channel_id'</span><span class="p">]},</span>
      <span class="p">{</span><span class="s1">'columns'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'date_id'</span><span class="p">]}</span>
    <span class="p">]</span>
  <span class="p">)</span>
<span class="p">}}</span>

<span class="k">with</span> <span class="n">stg_sales</span> <span class="k">as</span> <span class="p">(</span>
    <span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="p">{{</span> <span class="k">ref</span><span class="p">(</span><span class="s1">'stg_sales'</span><span class="p">)</span> <span class="p">}}</span>
<span class="p">),</span>

<span class="n">dim_product</span> <span class="k">as</span> <span class="p">(</span>
    <span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="p">{{</span> <span class="k">ref</span><span class="p">(</span><span class="s1">'dim_product'</span><span class="p">)</span> <span class="p">}}</span>
<span class="p">),</span>

<span class="n">dim_location</span> <span class="k">as</span> <span class="p">(</span>
    <span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="p">{{</span> <span class="k">ref</span><span class="p">(</span><span class="s1">'dim_location'</span><span class="p">)</span> <span class="p">}}</span>
<span class="p">),</span>

<span class="c1">-- Create dimension references for retailer and channel</span>
<span class="n">dim_retailer</span> <span class="k">as</span> <span class="p">(</span>
    <span class="k">select</span> <span class="k">distinct</span>
        <span class="n">retailer_id</span><span class="p">,</span>
        <span class="n">retailer_name</span>
    <span class="k">from</span> <span class="n">stg_sales</span>
<span class="p">),</span>

<span class="n">dim_channel</span> <span class="k">as</span> <span class="p">(</span>
    <span class="k">select</span>
        <span class="n">channel</span><span class="p">,</span>
        <span class="p">{{</span> <span class="n">dbt_utils</span><span class="p">.</span><span class="n">generate_surrogate_key</span><span class="p">([</span><span class="s1">'channel'</span><span class="p">])</span> <span class="p">}}</span> <span class="k">as</span> <span class="n">channel_id</span>
    <span class="k">from</span> <span class="n">stg_sales</span>
    <span class="k">group</span> <span class="k">by</span> <span class="n">channel</span>
<span class="p">),</span>

<span class="c1">-- Final fact sales table</span>
<span class="k">final</span> <span class="k">as</span> <span class="p">(</span>
    <span class="k">select</span>
        <span class="n">s</span><span class="p">.</span><span class="n">sale_id</span><span class="p">,</span>
        <span class="n">s</span><span class="p">.</span><span class="n">product_id</span><span class="p">,</span>
        <span class="n">s</span><span class="p">.</span><span class="n">retailer_id</span><span class="p">,</span>
        <span class="n">l</span><span class="p">.</span><span class="n">location_id</span><span class="p">,</span>
        <span class="k">c</span><span class="p">.</span><span class="n">channel_id</span><span class="p">,</span>
        <span class="n">s</span><span class="p">.</span><span class="nb">date</span> <span class="k">as</span> <span class="n">date_id</span><span class="p">,</span>
        <span class="n">s</span><span class="p">.</span><span class="n">quantity</span><span class="p">,</span>
        <span class="n">s</span><span class="p">.</span><span class="n">price</span> <span class="o">/</span> <span class="k">nullif</span><span class="p">(</span><span class="n">s</span><span class="p">.</span><span class="n">quantity</span><span class="p">,</span> <span class="mi">0</span><span class="p">)::</span><span class="nb">numeric</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="k">as</span> <span class="n">unit_price</span><span class="p">,</span>
        <span class="n">s</span><span class="p">.</span><span class="n">price</span><span class="p">::</span><span class="nb">numeric</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="k">as</span> <span class="n">total_amount</span><span class="p">,</span>
        <span class="n">s</span><span class="p">.</span><span class="n">transformed_at</span>
    <span class="k">from</span> <span class="n">stg_sales</span> <span class="n">s</span>
    <span class="k">inner</span> <span class="k">join</span> <span class="n">dim_location</span> <span class="n">l</span> <span class="k">on</span> <span class="n">l</span><span class="p">.</span><span class="k">location</span> <span class="o">=</span> <span class="n">s</span><span class="p">.</span><span class="k">location</span>
    <span class="k">inner</span> <span class="k">join</span> <span class="n">dim_channel</span> <span class="k">c</span> <span class="k">on</span> <span class="k">c</span><span class="p">.</span><span class="n">channel</span> <span class="o">=</span> <span class="n">s</span><span class="p">.</span><span class="n">channel</span>
    <span class="p">{</span><span class="o">%</span> <span class="n">if</span> <span class="n">is_incremental</span><span class="p">()</span> <span class="o">%</span><span class="p">}</span>
    <span class="k">where</span> <span class="n">s</span><span class="p">.</span><span class="n">transformed_at</span> <span class="o">&gt;</span> <span class="p">(</span><span class="k">select</span> <span class="k">max</span><span class="p">(</span><span class="n">transformed_at</span><span class="p">)</span> <span class="k">from</span> <span class="p">{{</span> <span class="n">this</span> <span class="p">}})</span>
    <span class="p">{</span><span class="o">%</span> <span class="n">endif</span> <span class="o">%</span><span class="p">}</span>
<span class="p">)</span>

<span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="k">final</span>

</pre></table></code></div></div><h3 id="4-orchestration-with-airflow"><span class="mr-2">4. Orchestration with Airflow</span><a href="#4-orchestration-with-airflow" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>The Airflow DAGs orchestrate the entire pipeline. I implemented two primary DAGs:</p><ol><li>The Sales Data Pipeline for ingestion and initial transformation:</ol><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="c1"># Define task dependencies
</span><span class="n">check_file_exists</span> <span class="o">&gt;&gt;</span> <span class="n">check_and_ingest_data</span> <span class="o">&gt;&gt;</span> <span class="n">transform_raw_data</span> <span class="o">&gt;&gt;</span> <span class="n">archive_file</span>
</pre></table></code></div></div><ol><li>The dbt Transformation Pipeline for analytical models:</ol><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
</pre><td class="rouge-code"><pre><span class="c1"># Define dbt commands
</span><span class="n">dbt_deps_cmd</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"""
cd </span><span class="si">{</span><span class="n">DBT_PROJECT_DIR</span><span class="si">}</span><span class="s"> &amp;&amp; 
dbt deps --profiles-dir </span><span class="si">{</span><span class="n">DBT_PROFILES_DIR</span><span class="si">}</span><span class="s"> --target </span><span class="si">{</span><span class="n">DBT_TARGET</span><span class="si">}</span><span class="s">
"""</span>

<span class="n">dbt_run_staging_cmd</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"""
cd </span><span class="si">{</span><span class="n">DBT_PROJECT_DIR</span><span class="si">}</span><span class="s"> &amp;&amp; 
dbt run --models "staging.*" --profiles-dir </span><span class="si">{</span><span class="n">DBT_PROFILES_DIR</span><span class="si">}</span><span class="s"> --target </span><span class="si">{</span><span class="n">DBT_TARGET</span><span class="si">}</span><span class="s">
"""</span>

<span class="n">dbt_run_marts_cmd</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"""
cd </span><span class="si">{</span><span class="n">DBT_PROJECT_DIR</span><span class="si">}</span><span class="s"> &amp;&amp; 
dbt run --models "marts.*" --profiles-dir </span><span class="si">{</span><span class="n">DBT_PROFILES_DIR</span><span class="si">}</span><span class="s"> --target </span><span class="si">{</span><span class="n">DBT_TARGET</span><span class="si">}</span><span class="s">
"""</span>

<span class="n">dbt_test_cmd</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"""
cd </span><span class="si">{</span><span class="n">DBT_PROJECT_DIR</span><span class="si">}</span><span class="s"> &amp;&amp; 
dbt test --profiles-dir </span><span class="si">{</span><span class="n">DBT_PROFILES_DIR</span><span class="si">}</span><span class="s"> --target </span><span class="si">{</span><span class="n">DBT_TARGET</span><span class="si">}</span><span class="s">
"""</span>

<span class="c1"># Define task dependencies
</span><span class="n">check_and_ingest_data</span> <span class="o">&gt;&gt;</span> <span class="n">install_dependencies</span> <span class="o">&gt;&gt;</span> <span class="n">run_staging_models</span> <span class="o">&gt;&gt;</span> <span class="n">run_mart_models</span> <span class="o">&gt;&gt;</span> <span class="n">test_models</span>
</pre></table></code></div></div><h2 id="advanced-features"><span class="mr-2">Advanced Features</span><a href="#advanced-features" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h3 id="self-healing-data-flow"><span class="mr-2">Self-healing Data Flow</span><a href="#self-healing-data-flow" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>A key feature of this pipeline is its “self-healing” capability. Both DAGs automatically check if the required data exists before proceeding, and trigger upstream processes if needed:</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
</pre><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">RawDataSensor</span><span class="p">(</span><span class="n">BaseSensorOperator</span><span class="p">):</span>
    <span class="s">"""
    Sensor to check if there's data in the raw.sales table.
    """</span>
    <span class="o">@</span><span class="n">apply_defaults</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">conn_id</span><span class="o">=</span><span class="s">"sales_db"</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">conn_id</span> <span class="o">=</span> <span class="n">conn_id</span>

    <span class="k">def</span> <span class="nf">poke</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
        <span class="n">hook</span> <span class="o">=</span> <span class="n">PostgresHook</span><span class="p">(</span><span class="n">postgres_conn_id</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">conn_id</span><span class="p">)</span>
        <span class="n">sql</span> <span class="o">=</span> <span class="s">"SELECT COUNT(*) FROM raw.sales"</span>
        <span class="n">count</span> <span class="o">=</span> <span class="n">hook</span><span class="p">.</span><span class="n">get_first</span><span class="p">(</span><span class="n">sql</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">log</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s">"Found </span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="s"> rows in raw.sales table"</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">count</span> <span class="o">&gt;</span> <span class="mi">0</span>


<span class="k">def</span> <span class="nf">check_and_ingest_data</span><span class="p">(</span><span class="n">csv_file_path</span><span class="p">,</span> <span class="n">conn_id</span><span class="o">=</span><span class="s">"sales_db"</span><span class="p">,</span> <span class="o">**</span><span class="n">context</span><span class="p">):</span>
    <span class="s">"""
    Check if data exists in raw.sales and ingest if empty.
    """</span>
    <span class="n">hook</span> <span class="o">=</span> <span class="n">PostgresHook</span><span class="p">(</span><span class="n">postgres_conn_id</span><span class="o">=</span><span class="n">conn_id</span><span class="p">)</span>
    
    <span class="c1"># Check if data exists
</span>    <span class="n">sql</span> <span class="o">=</span> <span class="s">"SELECT COUNT(*) FROM raw.sales"</span>
    <span class="n">count</span> <span class="o">=</span> <span class="n">hook</span><span class="p">.</span><span class="n">get_first</span><span class="p">(</span><span class="n">sql</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="c1"># If data exists, return True
</span>    <span class="k">if</span> <span class="n">count</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">context</span><span class="p">[</span><span class="s">'ti'</span><span class="p">].</span><span class="n">xcom_push</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="s">'data_already_exists'</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">True</span>
    
    <span class="c1"># If no data, perform ingestion
</span>    <span class="k">try</span><span class="p">:</span>
        <span class="n">ingest_main</span> <span class="o">=</span> <span class="n">import_ingest_module</span><span class="p">()</span>
        <span class="n">records_loaded</span> <span class="o">=</span> <span class="n">ingest_main</span><span class="p">(</span><span class="n">csv_file_path</span><span class="p">)</span>
        
        <span class="c1"># Verify ingestion was successful
</span>        <span class="k">if</span> <span class="n">records_loaded</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">context</span><span class="p">[</span><span class="s">'ti'</span><span class="p">].</span><span class="n">xcom_push</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="s">'records_loaded'</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">records_loaded</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">context</span><span class="p">[</span><span class="s">'ti'</span><span class="p">].</span><span class="n">xcom_push</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="s">'ingest_failed'</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">False</span>
    <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">context</span><span class="p">[</span><span class="s">'ti'</span><span class="p">].</span><span class="n">xcom_push</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="s">'ingest_error'</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">))</span>
        <span class="k">raise</span>
</pre></table></code></div></div><p>This design enables either pipeline to be triggered independently without failures, creating a more resilient system.</p><h3 id="data-quality-testing"><span class="mr-2">Data Quality Testing</span><a href="#data-quality-testing" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Comprehensive data quality checks are implemented in both Python and dbt:</p><ol><li>Python validation for source data:</ol><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">validate_data</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
    <span class="s">"""
    Validate data quality and identify invalid records.
    Returns a boolean indicating if the data is valid and a list of invalid indices.
    """</span>
    <span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s">"Validating data... Total records: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    
    <span class="c1"># Track invalid rows for logging
</span>    <span class="n">invalid_rows</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s">'dates'</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s">'quantities'</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s">'prices'</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s">'all'</span><span class="p">:</span> <span class="nb">set</span><span class="p">()</span>  <span class="c1"># Use a set to avoid duplicates
</span>    <span class="p">}</span>
    
    <span class="c1"># Check for invalid dates
</span>    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">date_str</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'Date'</span><span class="p">]):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Try to parse the date
</span>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">date_str</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">date_str</span><span class="p">:</span>
                <span class="c1"># Handle different date formats
</span>                <span class="k">if</span> <span class="s">'/'</span> <span class="ow">in</span> <span class="n">date_str</span><span class="p">:</span>
                    <span class="n">datetime</span><span class="p">.</span><span class="n">strptime</span><span class="p">(</span><span class="n">date_str</span><span class="p">,</span> <span class="s">'%Y/%m/%d'</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">datetime</span><span class="p">.</span><span class="n">strptime</span><span class="p">(</span><span class="n">date_str</span><span class="p">,</span> <span class="s">'%Y-%m-%d'</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Empty or non-string date
</span>                <span class="n">invalid_rows</span><span class="p">[</span><span class="s">'dates'</span><span class="p">].</span><span class="n">append</span><span class="p">((</span><span class="n">idx</span><span class="p">,</span> <span class="n">date_str</span><span class="p">))</span>
                <span class="n">invalid_rows</span><span class="p">[</span><span class="s">'all'</span><span class="p">].</span><span class="n">add</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
        <span class="k">except</span> <span class="nb">ValueError</span><span class="p">:</span>
            <span class="n">invalid_rows</span><span class="p">[</span><span class="s">'dates'</span><span class="p">].</span><span class="n">append</span><span class="p">((</span><span class="n">idx</span><span class="p">,</span> <span class="n">date_str</span><span class="p">))</span>
            <span class="n">invalid_rows</span><span class="p">[</span><span class="s">'all'</span><span class="p">].</span><span class="n">add</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
    
    <span class="c1"># More validation checks...
</span>    
    <span class="k">return</span> <span class="n">is_valid</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">invalid_rows</span><span class="p">[</span><span class="s">'all'</span><span class="p">])</span>
</pre></table></code></div></div><ol><li>dbt tests for transformed data:</ol><div class="language-yaml highlighter-rouge"><div class="code-header"> <span data-label-text="YAML"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
</pre><td class="rouge-code"><pre><span class="c1"># schema.yml for fact_sales</span>
<span class="na">version</span><span class="pi">:</span> <span class="m">2</span>

<span class="na">models</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">fact_sales</span>
    <span class="na">description</span><span class="pi">:</span> <span class="s2">"</span><span class="s">Fact</span><span class="nv"> </span><span class="s">table</span><span class="nv"> </span><span class="s">for</span><span class="nv"> </span><span class="s">sales</span><span class="nv"> </span><span class="s">with</span><span class="nv"> </span><span class="s">related</span><span class="nv"> </span><span class="s">dimension</span><span class="nv"> </span><span class="s">keys"</span>
    <span class="na">columns</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">sale_id</span>
        <span class="na">description</span><span class="pi">:</span> <span class="s2">"</span><span class="s">The</span><span class="nv"> </span><span class="s">primary</span><span class="nv"> </span><span class="s">key</span><span class="nv"> </span><span class="s">for</span><span class="nv"> </span><span class="s">the</span><span class="nv"> </span><span class="s">sales</span><span class="nv"> </span><span class="s">transaction"</span>
        <span class="na">tests</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="s">unique</span>
          <span class="pi">-</span> <span class="s">not_null</span>
      
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">product_id</span>
        <span class="na">description</span><span class="pi">:</span> <span class="s2">"</span><span class="s">Foreign</span><span class="nv"> </span><span class="s">key</span><span class="nv"> </span><span class="s">to</span><span class="nv"> </span><span class="s">product</span><span class="nv"> </span><span class="s">dimension"</span>
        <span class="na">tests</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="s">not_null</span>
          <span class="pi">-</span> <span class="na">relationships</span><span class="pi">:</span>
              <span class="na">to</span><span class="pi">:</span> <span class="s">ref('dim_product')</span>
              <span class="na">field</span><span class="pi">:</span> <span class="s">product_id</span>
      
      <span class="c1"># Additional column tests...</span>
      
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">quantity</span>
        <span class="na">description</span><span class="pi">:</span> <span class="s2">"</span><span class="s">Number</span><span class="nv"> </span><span class="s">of</span><span class="nv"> </span><span class="s">items</span><span class="nv"> </span><span class="s">sold"</span>
        <span class="na">tests</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="s">not_null</span>
          <span class="pi">-</span> <span class="s">positive_values</span>
</pre></table></code></div></div><h3 id="incremental-processing"><span class="mr-2">Incremental Processing</span><a href="#incremental-processing" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>The pipeline implements incremental processing at multiple levels:</p><ol><li>Python-based ETL uses ID-based tracking:</ol><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre><span class="c1"># Query to get only new records 
</span><span class="n">query</span> <span class="o">=</span> <span class="s">"""
SELECT "SaleID", "ProductID", "RetailerID", "Channel", "Location", 
       "Quantity", "Price", "Date"
FROM raw.sales
WHERE "SaleID" NOT IN (
    SELECT sale_id::VARCHAR FROM transformed.fact_sales
)
ORDER BY "SaleID" ASC
"""</span>
</pre></table></code></div></div><ol><li>dbt models use incremental materialization:</ol><div class="language-sql highlighter-rouge"><div class="code-header"> <span data-label-text="Sql"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>
<span class="p">{</span><span class="o">%</span> <span class="n">if</span> <span class="n">is_incremental</span><span class="p">()</span> <span class="o">%</span><span class="p">}</span>
<span class="k">where</span> <span class="n">s</span><span class="p">.</span><span class="n">transformed_at</span> <span class="o">&gt;</span> <span class="p">(</span><span class="k">select</span> <span class="k">max</span><span class="p">(</span><span class="n">transformed_at</span><span class="p">)</span> <span class="k">from</span> <span class="p">{{</span> <span class="n">this</span> <span class="p">}})</span>
<span class="p">{</span><span class="o">%</span> <span class="n">endif</span> <span class="o">%</span><span class="p">}</span>

</pre></table></code></div></div><p>This two-tiered approach ensures efficient processing of only new or changed data.</p><h2 id="containerization-and-deployment"><span class="mr-2">Containerization and Deployment</span><a href="#containerization-and-deployment" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>The entire solution is containerized using Docker for consistent deployment:</p><div class="language-yaml highlighter-rouge"><div class="code-header"> <span data-label-text="YAML"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
</pre><td class="rouge-code"><pre><span class="na">services</span><span class="pi">:</span>
  <span class="na">postgres</span><span class="pi">:</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">postgres:latest</span>
    <span class="na">environment</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">POSTGRES_USER=postgres</span>
      <span class="pi">-</span> <span class="s">POSTGRES_PASSWORD=mysecretpassword</span>
      <span class="pi">-</span> <span class="s">POSTGRES_MULTIPLE_DATABASES=airflow,sales</span>
    <span class="na">volumes</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">./initdb:/docker-entrypoint-initdb.d</span>
      <span class="pi">-</span> <span class="s">postgres-db-volume:/var/lib/postgresql/data</span>
    <span class="na">healthcheck</span><span class="pi">:</span>
      <span class="na">test</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">CMD"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">pg_isready"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">-U"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">postgres"</span><span class="pi">]</span>
      <span class="na">interval</span><span class="pi">:</span> <span class="s">5s</span>
      <span class="na">retries</span><span class="pi">:</span> <span class="m">5</span>
    <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">5433:5432"</span>
    <span class="na">restart</span><span class="pi">:</span> <span class="s">always</span>

  <span class="na">airflow-webserver</span><span class="pi">:</span>
    <span class="na">&lt;&lt;</span><span class="pi">:</span> <span class="nv">*airflow-common</span>
    <span class="na">command</span><span class="pi">:</span> <span class="s">webserver</span>
    <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">8081:8080</span>
    <span class="na">healthcheck</span><span class="pi">:</span>
      <span class="na">test</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">CMD"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">curl"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">--fail"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">http://localhost:8081/health"</span><span class="pi">]</span>
      <span class="na">interval</span><span class="pi">:</span> <span class="s">10s</span>
      <span class="na">timeout</span><span class="pi">:</span> <span class="s">10s</span>
      <span class="na">retries</span><span class="pi">:</span> <span class="m">5</span>
    <span class="na">restart</span><span class="pi">:</span> <span class="s">always</span>

  <span class="c1"># Additional services...</span>
</pre></table></code></div></div><h2 id="scalability-approaches"><span class="mr-2">Scalability Approaches</span><a href="#scalability-approaches" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>As the data volume grows, several scalability enhancements can be implemented:</p><h3 id="1-partitioning-for-larger-datasets"><span class="mr-2">1. Partitioning for Larger Datasets</span><a href="#1-partitioning-for-larger-datasets" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>For larger datasets, implementing table partitioning in PostgreSQL can significantly improve performance:</p><div class="language-sql highlighter-rouge"><div class="code-header"> <span data-label-text="Sql"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre><td class="rouge-code"><pre><span class="c1">-- Example of adding partitioning to fact_sales</span>
<span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">analytics</span><span class="p">.</span><span class="n">fact_sales</span> <span class="p">(</span>
    <span class="n">sale_id</span> <span class="nb">INTEGER</span><span class="p">,</span>
    <span class="c1">-- other columns...</span>
    <span class="n">date_id</span> <span class="nb">DATE</span> <span class="k">NOT</span> <span class="k">NULL</span>
<span class="p">)</span> <span class="k">PARTITION</span> <span class="k">BY</span> <span class="k">RANGE</span> <span class="p">(</span><span class="n">date_id</span><span class="p">);</span>

<span class="c1">-- Create partitions by month</span>
<span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">fact_sales_2024_q1</span> <span class="k">PARTITION</span> <span class="k">OF</span> <span class="n">fact_sales</span>
    <span class="k">FOR</span> <span class="k">VALUES</span> <span class="k">FROM</span> <span class="p">(</span><span class="s1">'2024-01-01'</span><span class="p">)</span> <span class="k">TO</span> <span class="p">(</span><span class="s1">'2024-04-01'</span><span class="p">);</span>

<span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">fact_sales_2024_q2</span> <span class="k">PARTITION</span> <span class="k">OF</span> <span class="n">fact_sales</span>
    <span class="k">FOR</span> <span class="k">VALUES</span> <span class="k">FROM</span> <span class="p">(</span><span class="s1">'2024-04-01'</span><span class="p">)</span> <span class="k">TO</span> <span class="p">(</span><span class="s1">'2024-07-01'</span><span class="p">);</span>
</pre></table></code></div></div><h3 id="2-parallel-processing-with-airflow"><span class="mr-2">2. Parallel Processing with Airflow</span><a href="#2-parallel-processing-with-airflow" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>For processing large volumes of data, implementing parallel task execution in Airflow:</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre><span class="c1"># Create parallel tasks for processing different data segments
</span><span class="k">for</span> <span class="n">segment</span> <span class="ow">in</span> <span class="n">get_data_segments</span><span class="p">():</span>
    <span class="n">process_segment</span> <span class="o">=</span> <span class="n">PythonOperator</span><span class="p">(</span>
        <span class="n">task_id</span><span class="o">=</span><span class="sa">f</span><span class="s">'process_segment_</span><span class="si">{</span><span class="n">segment</span><span class="si">}</span><span class="s">'</span><span class="p">,</span>
        <span class="n">python_callable</span><span class="o">=</span><span class="n">process_data_segment</span><span class="p">,</span>
        <span class="n">op_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s">'segment'</span><span class="p">:</span> <span class="n">segment</span><span class="p">},</span>
        <span class="n">dag</span><span class="o">=</span><span class="n">dag</span><span class="p">,</span>
    <span class="p">)</span>
    
    <span class="c1"># Set dependencies
</span>    <span class="n">check_and_ingest_data</span> <span class="o">&gt;&gt;</span> <span class="n">process_segment</span> <span class="o">&gt;&gt;</span> <span class="n">merge_segments</span>
</pre></table></code></div></div><h3 id="3-enhanced-incremental-processing"><span class="mr-2">3. Enhanced Incremental Processing</span><a href="#3-enhanced-incremental-processing" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>The current incremental approach can be enhanced with timestamp-based windowing:</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">extract_incremental_data</span><span class="p">(</span><span class="n">start_time</span><span class="p">,</span> <span class="n">end_time</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10000</span><span class="p">):</span>
    <span class="s">"""Extract data in time-bounded batches for efficient processing."""</span>
    <span class="n">current_position</span> <span class="o">=</span> <span class="n">start_time</span>
    
    <span class="k">while</span> <span class="n">current_position</span> <span class="o">&lt;</span> <span class="n">end_time</span><span class="p">:</span>
        <span class="n">next_position</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">current_position</span> <span class="o">+</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">hours</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">end_time</span><span class="p">)</span>
        
        <span class="n">query</span> <span class="o">=</span> <span class="s">"""
        SELECT * FROM raw.sales
        WHERE inserted_at &gt;= %s AND inserted_at &lt; %s
        ORDER BY inserted_at
        LIMIT %s
        """</span>
        
        <span class="k">yield</span> <span class="n">execute_query</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="p">(</span><span class="n">current_position</span><span class="p">,</span> <span class="n">next_position</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">))</span>
        <span class="n">current_position</span> <span class="o">=</span> <span class="n">next_position</span>
</pre></table></code></div></div><p>This approach reduces memory pressure when dealing with large datasets.</p><h2 id="optimization-techniques"><span class="mr-2">Optimization Techniques</span><a href="#optimization-techniques" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h3 id="1-database-indexing-strategy"><span class="mr-2">1. Database Indexing Strategy</span><a href="#1-database-indexing-strategy" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Carefully designed indexes dramatically improve query performance:</p><div class="language-sql highlighter-rouge"><div class="code-header"> <span data-label-text="Sql"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="c1">-- Indexes for the fact table</span>
<span class="k">CREATE</span> <span class="k">INDEX</span> <span class="n">idx_fact_sales_product_id</span> <span class="k">ON</span> <span class="n">transformed</span><span class="p">.</span><span class="n">fact_sales</span><span class="p">(</span><span class="n">product_id</span><span class="p">);</span>
<span class="k">CREATE</span> <span class="k">INDEX</span> <span class="n">idx_fact_sales_retailer_id</span> <span class="k">ON</span> <span class="n">transformed</span><span class="p">.</span><span class="n">fact_sales</span><span class="p">(</span><span class="n">retailer_id</span><span class="p">);</span>
<span class="k">CREATE</span> <span class="k">INDEX</span> <span class="n">idx_fact_sales_date_id</span> <span class="k">ON</span> <span class="n">transformed</span><span class="p">.</span><span class="n">fact_sales</span><span class="p">(</span><span class="n">date_id</span><span class="p">);</span>
<span class="k">CREATE</span> <span class="k">INDEX</span> <span class="n">idx_fact_sales_channel_id</span> <span class="k">ON</span> <span class="n">transformed</span><span class="p">.</span><span class="n">fact_sales</span><span class="p">(</span><span class="n">channel_id</span><span class="p">);</span>
</pre></table></code></div></div><h3 id="2-memory-efficient-processing"><span class="mr-2">2. Memory-Efficient Processing</span><a href="#2-memory-efficient-processing" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>For large datasets, implement batch processing to control memory usage:</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">process_large_dataset</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10000</span><span class="p">):</span>
    <span class="s">"""Process large CSV files in batches to control memory usage."""</span>
    <span class="c1"># Use pandas chunking for memory efficiency
</span>    <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="n">chunksize</span><span class="o">=</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="c1"># Validate and clean the chunk
</span>        <span class="n">is_valid</span><span class="p">,</span> <span class="n">invalid_indices</span> <span class="o">=</span> <span class="n">validate_data</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_valid</span><span class="p">:</span>
            <span class="n">chunk</span> <span class="o">=</span> <span class="n">CleanData</span><span class="p">.</span><span class="n">apply_all_cleaners</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
            <span class="n">chunk</span> <span class="o">=</span> <span class="n">filter_invalid_records</span><span class="p">(</span><span class="n">chunk</span><span class="p">,</span> <span class="n">invalid_indices</span><span class="p">)</span>
            
        <span class="c1"># Process the cleaned chunk
</span>        <span class="n">load_to_raw</span><span class="p">(</span><span class="n">chunk</span><span class="p">,</span> <span class="n">get_db_connection_string</span><span class="p">(),</span> <span class="n">file_path</span><span class="p">)</span>
</pre></table></code></div></div><h3 id="3-airflow-task-configuration"><span class="mr-2">3. Airflow Task Configuration</span><a href="#3-airflow-task-configuration" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Optimizing Airflow task configuration for better resource utilization:</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre><span class="c1"># Task configuration for better resource management
</span><span class="n">task</span> <span class="o">=</span> <span class="n">PythonOperator</span><span class="p">(</span>
    <span class="n">task_id</span><span class="o">=</span><span class="s">'transform_raw_data'</span><span class="p">,</span>
    <span class="n">python_callable</span><span class="o">=</span><span class="n">transform_main</span><span class="p">,</span>
    <span class="n">executor_config</span><span class="o">=</span><span class="p">{</span>
        <span class="s">'cpu_millicores'</span><span class="p">:</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="s">'memory_mb'</span><span class="p">:</span> <span class="mi">2048</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="n">dag</span><span class="o">=</span><span class="n">dag</span><span class="p">,</span>
<span class="p">)</span>
</pre></table></code></div></div><h2 id="conclusion"><span class="mr-2">Conclusion</span><a href="#conclusion" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>This data pipeline demonstrates how modern tools and architectural patterns can create a robust, production-ready data infrastructure. By combining Airflow’s orchestration capabilities with dbt’s transformation power and a well-designed schema, we’ve built a system that can handle real-world data challenges while maintaining flexibility for future growth.</p><p>Key takeaways from this implementation:</p><ol><li>The value of a layered architectural approach (medallion pattern)<li>The importance of separating validation from cleaning for better data quality management<li>The benefits of self-healing data flows that can recover from failures<li>How containerization provides environment consistency across development and production</ol><p>While no data pipeline is ever truly “complete” (data requirements evolve continuously), this implementation provides a solid foundation that can adapt to changing business needs. The patterns and practices demonstrated here can help create more resilient, maintainable data systems for organizations of any size.</p><p>The complete code for this project is available on GitHub at <a href="https://github.com/samuelTyh/airflow-dbt-sales-analytics">samuelTyh/airflow-dbt-sales-analytics</a>.</p><h2 id="future-work"><span class="mr-2">Future Work</span><a href="#future-work" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Looking ahead, this pipeline could be enhanced with:</p><ol><li><strong>Real-time streaming capabilities</strong>: Integrating a streaming solution like Kafka for near real-time data processing<li><strong>Advanced data quality monitoring</strong>: Adding automated data quality monitoring with Great Expectations or dbt expectations<li><strong>ML feature engineering</strong>: Extending the pipeline to generate features for machine learning models<li><strong>Cloud-native deployment</strong>: Adapting the architecture for cloud platforms with services like AWS Glue, Azure Data Factory, or Google Cloud Dataflow</ol><p>These enhancements would further extend the capabilities of the pipeline while maintaining the core architectural principles that make it reliable and maintainable.</p><p>What data pipeline patterns have you found most effective in your work? Share your thoughts and questions in the comments below!</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/data-engineering/'>Data Engineering</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/python/" class="post-tag no-text-decoration" >python</a> <a href="/tags/postgres/" class="post-tag no-text-decoration" >postgres</a> <a href="/tags/airflow/" class="post-tag no-text-decoration" >airflow</a> <a href="/tags/dbt/" class="post-tag no-text-decoration" >dbt</a> <a href="/tags/etl/" class="post-tag no-text-decoration" >etl</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Building+a+Production-Ready+Data+Pipeline+with+Airflow+and+dbt+-+samueltyh&url=https%3A%2F%2Fsamueltyh.github.io%2Fposts%2Fbuilding-a-production-ready-data-pipeline-with-airflow-and-dbt%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Building+a+Production-Ready+Data+Pipeline+with+Airflow+and+dbt+-+samueltyh&u=https%3A%2F%2Fsamueltyh.github.io%2Fposts%2Fbuilding-a-production-ready-data-pipeline-with-airflow-and-dbt%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fsamueltyh.github.io%2Fposts%2Fbuilding-a-production-ready-data-pipeline-with-airflow-and-dbt%2F&text=Building+a+Production-Ready+Data+Pipeline+with+Airflow+and+dbt+-+samueltyh" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/terraform-for-data-engineers-automating-your-data-infrastructure/">Terraform for Data Engineers: Automating Your Data Infrastructure</a><li><a href="/posts/how-to-train-a-customized-name-entities-recognition-ner-model-based-on-spacy-pre-trained-model/">How to train a customized Name Entities Recognition (NER) model based on spaCy pre-trained model</a><li><a href="/posts/run-your-own-apache-spark-jobs-in-aws-emr-and-s3/">Run your own Apache Spark jobs in AWS EMR and S3</a><li><a href="/posts/implementing-fivetran-data-source-connector-with-aws-lambda/">Implementing Fivetran Data Source Connector with AWS Lambda</a><li><a href="/posts/learning-and-takeaways-from-kubesimplify-workshop/">Learning and Takeaways from Kubesimplify Workshop</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/etl/">etl</a> <a class="post-tag" href="/tags/aws/">aws</a> <a class="post-tag" href="/tags/devops/">devops</a> <a class="post-tag" href="/tags/docker/">docker</a> <a class="post-tag" href="/tags/postgres/">postgres</a> <a class="post-tag" href="/tags/python/">python</a> <a class="post-tag" href="/tags/airflow/">airflow</a> <a class="post-tag" href="/tags/automation/">automation</a> <a class="post-tag" href="/tags/azure-data-studio/">azure-data-studio</a> <a class="post-tag" href="/tags/bash/">bash</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/building-a-scalable-etl-pipeline-for-adtech-analytics/"><div class="card-body"> <em class="small" data-ts="1745250420" data-df="ll" > Apr 21, 2025 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Building a Scalable ETL Pipeline for AdTech Analytics</h3><div class="text-muted small"><p> In the world of digital advertising, data is everything. Transforming raw operational data into actionable insights requires robust analytics pipelines. Recently, I implemented a comprehensive ETL ...</p></div></div></a></div><div class="card"> <a href="/posts/implementing-fivetran-data-source-connector-with-aws-lambda/"><div class="card-body"> <em class="small" data-ts="1653770820" data-df="ll" > May 28, 2022 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Implementing Fivetran Data Source Connector with AWS Lambda</h3><div class="text-muted small"><p> Basic background of AWS Lambda Official developer guide from AWS AWS Lambda is a serverless, event-driven compute service that lets you run code for virtually any type of application or backend s...</p></div></div></a></div><div class="card"> <a href="/posts/run-your-own-apache-spark-jobs-in-aws-emr-and-s3/"><div class="card-body"> <em class="small" data-ts="1612137600" data-df="ll" > Feb 1, 2021 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Run your own Apache Spark jobs in AWS EMR and S3</h3><div class="text-muted small"><p> Run your own Apache Spark jobs in AWS EMR and S3 Recently, I participated in Udacity’s Nanodegree Program for Data Engineers. It’s kinda like to review what I did past and refresh some tech stacks...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/building-a-scalable-etl-pipeline-for-adtech-analytics/" class="btn btn-outline-primary" prompt="Older"><p>Building a Scalable ETL Pipeline for AdTech Analytics</p></a> <a href="/posts/terraform-for-data-engineers-automating-your-data-infrastructure/" class="btn btn-outline-primary" prompt="Newer"><p>Terraform for Data Engineers: Automating Your Data Infrastructure</p></a></div><div id="disqus_thread" class="pt-2 pb-2"><p class="text-center text-muted small"> Comments powered by <a href="https://disqus.com/">Disqus</a>.</p></div><script type="text/javascript"> var disqus_config = function () { this.page.url = 'https://samueltyh.github.io/posts/building-a-production-ready-data-pipeline-with-airflow-and-dbt/'; this.page.identifier = '/posts/building-a-production-ready-data-pipeline-with-airflow-and-dbt/'; }; /* Lazy loading */ var disqus_observer = new IntersectionObserver(function (entries) { if(entries[0].isIntersecting) { (function () { var d = document, s = d.createElement('script'); s.src = 'https://samuelTyh.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); disqus_observer.disconnect(); } }, { threshold: [0] }); disqus_observer.observe(document.querySelector('#disqus_thread')); /* Auto switch theme */ function reloadDisqus() { /* Disqus hasn't been loaded */ if (typeof DISQUS === "undefined") { return; } if (document.readyState == 'complete') { DISQUS.reset({ reload: true, config: disqus_config }); } } const modeToggle = document.querySelector(".mode-toggle"); if (typeof modeToggle !== "undefined") { /* modeToggle.addEventListener('click', reloadDisqus); // not pretty for 'color-scheme' */ window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', reloadDisqus); } </script></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> © 2025 <a href="https://twitter.com/samueltyh">Samuel Tseng</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/etl/">etl</a> <a class="post-tag" href="/tags/aws/">aws</a> <a class="post-tag" href="/tags/devops/">devops</a> <a class="post-tag" href="/tags/docker/">docker</a> <a class="post-tag" href="/tags/postgres/">postgres</a> <a class="post-tag" href="/tags/python/">python</a> <a class="post-tag" href="/tags/airflow/">airflow</a> <a class="post-tag" href="/tags/automation/">automation</a> <a class="post-tag" href="/tags/azure-data-studio/">azure-data-studio</a> <a class="post-tag" href="/tags/bash/">bash</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/de.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-7X84VGPKQ1"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-7X84VGPKQ1'); }); </script>
