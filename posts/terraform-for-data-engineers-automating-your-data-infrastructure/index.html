<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="prefer-datetime-locale" content="de"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="Terraform for Data Engineers: Automating Your Data Infrastructure" /><meta property="og:locale" content="en" /><meta name="description" content="A comprehensive walkthrough of Terraform for Data Engineers." /><meta property="og:description" content="A comprehensive walkthrough of Terraform for Data Engineers." /><link rel="canonical" href="https://samueltyh.github.io/posts/terraform-for-data-engineers-automating-your-data-infrastructure/" /><meta property="og:url" content="https://samueltyh.github.io/posts/terraform-for-data-engineers-automating-your-data-infrastructure/" /><meta property="og:site_name" content="samueltyh" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2025-05-06T21:34:00+02:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Terraform for Data Engineers: Automating Your Data Infrastructure" /><meta name="twitter:site" content="@samueltyh" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-05-07T11:37:11+02:00","datePublished":"2025-05-06T21:34:00+02:00","description":"A comprehensive walkthrough of Terraform for Data Engineers.","headline":"Terraform for Data Engineers: Automating Your Data Infrastructure","mainEntityOfPage":{"@type":"WebPage","@id":"https://samueltyh.github.io/posts/terraform-for-data-engineers-automating-your-data-infrastructure/"},"url":"https://samueltyh.github.io/posts/terraform-for-data-engineers-automating-your-data-infrastructure/"}</script><title>Terraform for Data Engineers: Automating Your Data Infrastructure | samueltyh</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="samueltyh"><meta name="application-name" content="samueltyh"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> <img src="/assets/img/AvatarMaker.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">samueltyh</a></div><div class="site-subtitle font-italic">DevOps, Data Engineering, Data Science</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/samueltyh" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/samueltyh" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['samueltseng','icloud.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Terraform for Data Engineers: Automating Your Data Infrastructure</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Terraform for Data Engineers: Automating Your Data Infrastructure</h1><div class="post-meta text-muted"> <span> Posted <em class="" data-ts="1746560040" data-df="ll" data-toggle="tooltip" data-placement="bottom"> May 6, 2025 </em> </span> <span> Updated <em class="" data-ts="1746610631" data-df="ll" data-toggle="tooltip" data-placement="bottom"> May 7, 2025 </em> </span><div class="d-flex justify-content-between"> <span> By <em> <a href="https://twitter.com/samueltyh">Samuel Tseng</a> </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1656 words"> <em>9 min</em> read</span></div></div></div><div class="post-content"><p>As a data engineer, weâ€™re all too familiar with the pain of manually provisioning data processing resources, dealing with inconsistent environments, and the nightmare of trying to recreate a failed data pipeline. Enter Terraform â€“ a powerful tool that lets us define our entire data infrastructure as code, making it versionable, repeatable, and automated.</p><h2 id="what-is-terraform"><span class="mr-2">What is Terraform?</span><a href="#what-is-terraform" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Terraform is an infrastructure as code tool that allows you to define, provision, and manage cloud resources across providers like AWS, GCP, and Azure using a simple, declarative language. Instead of clicking through console UIs or writing custom scripts, you write configuration files that describe your desired infrastructure state, and Terraform makes it happen.</p><p>What makes Terraform particularly valuable for data engineers is its ability to provision and manage all the components of modern data platforms â€“ from storage and compute resources to data warehouses, ETL services, and analytics tools â€“ using a consistent workflow.</p><h2 id="how-terraform-fits-into-data-engineering"><span class="mr-2">How Terraform Fits into Data Engineering</span><a href="#how-terraform-fits-into-data-engineering" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>As data infrastructure grows more complex, crossing multiple cloud platforms and including dozens of specialized services, the old approach of manual provisioning becomes untenable. Terraform addresses this by:</p><ol><li><strong>Automating repetitive tasks</strong> - Set up data lakes, data warehouses, and compute clusters with code rather than click-ops<li><strong>Standardizing environments</strong> - Ensure development, staging, and production environments are identical<li><strong>Enabling infrastructure evolution</strong> - Version control your data infrastructure alongside your code<li><strong>Supporting collaboration</strong> - Let team members understand and contribute to infrastructure changes</ol><h2 id="terraform-basics-for-data-engineers"><span class="mr-2">Terraform Basics for Data Engineers</span><a href="#terraform-basics-for-data-engineers" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Terraform uses HashiCorp Configuration Language (HCL) for its configuration files. Hereâ€™s a simple example showing how to set up an AWS S3 bucket for data lake storage:</p><div class="language-hcl highlighter-rouge"><div class="code-header"> <span data-label-text="Hcl"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
</pre><td class="rouge-code"><pre><span class="nx">provider</span> <span class="s2">"aws"</span> <span class="p">{</span>
  <span class="nx">region</span> <span class="p">=</span> <span class="s2">"us-west-2"</span>
<span class="p">}</span>

<span class="c1"># Create an S3 bucket for our data lake</span>
<span class="nx">resource</span> <span class="s2">"aws_s3_bucket"</span> <span class="s2">"data_lake"</span> <span class="p">{</span>
  <span class="nx">bucket</span> <span class="p">=</span> <span class="s2">"my-company-data-lake"</span>
  
  <span class="nx">tags</span> <span class="p">=</span> <span class="p">{</span>
    <span class="nx">Environment</span> <span class="p">=</span> <span class="s2">"production"</span>
    <span class="nx">Department</span>  <span class="p">=</span> <span class="s2">"data-engineering"</span>
  <span class="p">}</span>
<span class="p">}</span>

<span class="c1"># Set up bucket for analytics results</span>
<span class="nx">resource</span> <span class="s2">"aws_s3_bucket"</span> <span class="s2">"analytics_results"</span> <span class="p">{</span>
  <span class="nx">bucket</span> <span class="p">=</span> <span class="s2">"my-company-analytics-results"</span>
  
  <span class="nx">tags</span> <span class="p">=</span> <span class="p">{</span>
    <span class="nx">Environment</span> <span class="p">=</span> <span class="s2">"production"</span>
    <span class="nx">Department</span>  <span class="p">=</span> <span class="s2">"data-engineering"</span>
  <span class="p">}</span>
<span class="p">}</span>
</pre></table></code></div></div><h3 id="the-basic-terraform-workflow"><span class="mr-2">The Basic Terraform Workflow</span><a href="#the-basic-terraform-workflow" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Working with Terraform follows a straightforward process:</p><ol><li><strong>Write</strong> your configuration in <code class="language-plaintext highlighter-rouge">.tf</code> files<li><strong>Init</strong> your project with <code class="language-plaintext highlighter-rouge">terraform init</code> to download providers<li><strong>Plan</strong> changes with <code class="language-plaintext highlighter-rouge">terraform plan</code> to see what will be created/modified<li><strong>Apply</strong> with <code class="language-plaintext highlighter-rouge">terraform apply</code> to create the resources<li><strong>Destroy</strong> with <code class="language-plaintext highlighter-rouge">terraform destroy</code> when youâ€™re done</ol><p>This workflow is particularly useful for data projects where you might need to spin up temporary analysis environments or test new pipeline architectures without committing to permanent infrastructure changes.</p><h2 id="data-engineering-use-cases-for-terraform"><span class="mr-2">Data Engineering Use Cases for Terraform</span><a href="#data-engineering-use-cases-for-terraform" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Letâ€™s dive into specific ways Terraform can solve your data engineering challenges:</p><h3 id="1-cloud-data-warehouse-provisioning"><span class="mr-2">1. Cloud Data Warehouse Provisioning</span><a href="#1-cloud-data-warehouse-provisioning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Setting up data warehouses like Redshift, BigQuery, or Snowflake requires numerous configuration choices. With Terraform, you can define these settings as code:</p><div class="language-hcl highlighter-rouge"><div class="code-header"> <span data-label-text="Hcl"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre><td class="rouge-code"><pre><span class="nx">resource</span> <span class="s2">"aws_redshift_cluster"</span> <span class="s2">"analytics_warehouse"</span> <span class="p">{</span>
  <span class="nx">cluster_identifier</span>  <span class="p">=</span> <span class="s2">"analytics-warehouse"</span>
  <span class="nx">database_name</span>       <span class="p">=</span> <span class="s2">"analytics"</span>
  <span class="nx">master_username</span>     <span class="p">=</span> <span class="nx">var</span><span class="err">.</span><span class="nx">redshift_admin_user</span>
  <span class="nx">master_password</span>     <span class="p">=</span> <span class="nx">var</span><span class="err">.</span><span class="nx">redshift_admin_password</span>
  <span class="nx">node_type</span>           <span class="p">=</span> <span class="s2">"dc2.large"</span>
  <span class="nx">cluster_type</span>        <span class="p">=</span> <span class="s2">"multi-node"</span>
  <span class="nx">number_of_nodes</span>     <span class="p">=</span> <span class="mi">3</span>
  
  <span class="c1"># Enable encryption and logging</span>
  <span class="nx">encrypted</span>           <span class="p">=</span> <span class="kc">true</span>
  <span class="nx">enhanced_vpc_routing</span> <span class="p">=</span> <span class="kc">true</span>
  <span class="nx">logging</span> <span class="p">{</span>
    <span class="nx">enable</span>            <span class="p">=</span> <span class="kc">true</span>
    <span class="nx">bucket_name</span>       <span class="p">=</span> <span class="nx">aws_s3_bucket</span><span class="err">.</span><span class="nx">redshift_logs</span><span class="err">.</span><span class="nx">bucket</span>
    <span class="nx">s3_key_prefix</span>     <span class="p">=</span> <span class="s2">"redshift-logs/"</span>
  <span class="p">}</span>
<span class="p">}</span>
</pre></table></code></div></div><p>This approach enables you to:</p><ul><li>Version control your warehouse configuration<li>Easily replicate the setup in development/testing environments<li>Automate warehouse scaling based on workload patterns</ul><h3 id="2-data-lake-infrastructure"><span class="mr-2">2. Data Lake Infrastructure</span><a href="#2-data-lake-infrastructure" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Modern data lakes involve many components beyond just storage. Terraform lets you provision the entire stack:</p><div class="language-hcl highlighter-rouge"><div class="code-header"> <span data-label-text="Hcl"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
</pre><td class="rouge-code"><pre><span class="c1"># S3 storage with proper partitioning setup</span>
<span class="nx">resource</span> <span class="s2">"aws_s3_bucket"</span> <span class="s2">"data_lake"</span> <span class="p">{</span>
  <span class="nx">bucket</span> <span class="p">=</span> <span class="s2">"company-data-lake"</span>
<span class="p">}</span>

<span class="c1"># Configure Glue Catalog for data discovery</span>
<span class="nx">resource</span> <span class="s2">"aws_glue_catalog_database"</span> <span class="s2">"data_catalog"</span> <span class="p">{</span>
  <span class="nx">name</span> <span class="p">=</span> <span class="s2">"data_lake_catalog"</span>
<span class="p">}</span>

<span class="c1"># Set up partitions and tables</span>
<span class="nx">resource</span> <span class="s2">"aws_glue_crawler"</span> <span class="s2">"data_crawler"</span> <span class="p">{</span>
  <span class="nx">name</span>          <span class="p">=</span> <span class="s2">"data-lake-crawler"</span>
  <span class="nx">role</span>          <span class="p">=</span> <span class="nx">aws_iam_role</span><span class="err">.</span><span class="nx">glue_role</span><span class="err">.</span><span class="nx">arn</span>
  <span class="nx">database_name</span> <span class="p">=</span> <span class="nx">aws_glue_catalog_database</span><span class="err">.</span><span class="nx">data_catalog</span><span class="err">.</span><span class="nx">name</span>
  
  <span class="nx">s3_target</span> <span class="p">{</span>
    <span class="nx">path</span> <span class="p">=</span> <span class="s2">"s3://${aws_s3_bucket.data_lake.bucket}/raw-data/"</span>
  <span class="p">}</span>
  
  <span class="nx">schedule</span> <span class="p">=</span> <span class="s2">"cron(0 */12 * * ? *)"</span>
<span class="p">}</span>

<span class="c1"># Add Athena workgroup for SQL queries</span>
<span class="nx">resource</span> <span class="s2">"aws_athena_workgroup"</span> <span class="s2">"analytics"</span> <span class="p">{</span>
  <span class="nx">name</span> <span class="p">=</span> <span class="s2">"data-engineering"</span>
  
  <span class="nx">configuration</span> <span class="p">{</span>
    <span class="nx">result_configuration</span> <span class="p">{</span>
      <span class="nx">output_location</span> <span class="p">=</span> <span class="s2">"s3://${aws_s3_bucket.query_results.bucket}/athena-results/"</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
</pre></table></code></div></div><h3 id="3-streaming-data-infrastructure"><span class="mr-2">3. Streaming Data Infrastructure</span><a href="#3-streaming-data-infrastructure" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Data engineers often need to set up real-time data processing pipelines. Terraform makes this easier by managing the complete infrastructure:</p><div class="language-hcl highlighter-rouge"><div class="code-header"> <span data-label-text="Hcl"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
</pre><td class="rouge-code"><pre><span class="c1"># Kafka cluster on MSK</span>
<span class="nx">resource</span> <span class="s2">"aws_msk_cluster"</span> <span class="s2">"event_streaming"</span> <span class="p">{</span>
  <span class="nx">cluster_name</span>           <span class="p">=</span> <span class="s2">"data-events-stream"</span>
  <span class="nx">kafka_version</span>          <span class="p">=</span> <span class="s2">"2.8.1"</span>
  <span class="nx">number_of_broker_nodes</span> <span class="p">=</span> <span class="mi">3</span>
  
  <span class="nx">broker_node_group_info</span> <span class="p">{</span>
    <span class="nx">instance_type</span>   <span class="p">=</span> <span class="s2">"kafka.m5.large"</span>
    <span class="nx">client_subnets</span>  <span class="p">=</span> <span class="nx">var</span><span class="err">.</span><span class="nx">private_subnets</span>
    <span class="nx">security_groups</span> <span class="p">=</span> <span class="p">[</span><span class="nx">aws_security_group</span><span class="err">.</span><span class="nx">kafka_sg</span><span class="err">.</span><span class="nx">id</span><span class="p">]</span>
    <span class="nx">storage_info</span> <span class="p">{</span>
      <span class="nx">ebs_storage_info</span> <span class="p">{</span>
        <span class="nx">volume_size</span> <span class="p">=</span> <span class="mi">1000</span>
      <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>

<span class="c1"># Kinesis Firehose for stream delivery to S3</span>
<span class="nx">resource</span> <span class="s2">"aws_kinesis_firehose_delivery_stream"</span> <span class="s2">"event_delivery"</span> <span class="p">{</span>
  <span class="nx">name</span>        <span class="p">=</span> <span class="s2">"event-delivery-stream"</span>
  <span class="nx">destination</span> <span class="p">=</span> <span class="s2">"extended_s3"</span>
  
  <span class="nx">extended_s3_configuration</span> <span class="p">{</span>
    <span class="nx">role_arn</span>   <span class="p">=</span> <span class="nx">aws_iam_role</span><span class="err">.</span><span class="nx">firehose_role</span><span class="err">.</span><span class="nx">arn</span>
    <span class="nx">bucket_arn</span> <span class="p">=</span> <span class="nx">aws_s3_bucket</span><span class="err">.</span><span class="nx">data_lake</span><span class="err">.</span><span class="nx">arn</span>
    <span class="nx">prefix</span>     <span class="p">=</span> <span class="s2">"streaming-events/year=!{timestamp:yyyy}/month=!{timestamp:MM}/day=!{timestamp:dd}/hour=!{timestamp:HH}/"</span>
    <span class="nx">buffer_interval</span> <span class="p">=</span> <span class="mi">60</span>
    <span class="nx">buffer_size</span>     <span class="p">=</span> <span class="mi">64</span>
  <span class="p">}</span>
<span class="p">}</span>
</pre></table></code></div></div><h3 id="4-compute-resources-for-data-processing"><span class="mr-2">4. Compute Resources for Data Processing</span><a href="#4-compute-resources-for-data-processing" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Spin up and manage compute resources for data transformation jobs:</p><div class="language-hcl highlighter-rouge"><div class="code-header"> <span data-label-text="Hcl"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
</pre><td class="rouge-code"><pre><span class="c1"># EMR cluster for Spark processing</span>
<span class="nx">resource</span> <span class="s2">"aws_emr_cluster"</span> <span class="s2">"data_processing"</span> <span class="p">{</span>
  <span class="nx">name</span>          <span class="p">=</span> <span class="s2">"data-processing-cluster"</span>
  <span class="nx">release_label</span> <span class="p">=</span> <span class="s2">"emr-6.5.0"</span>
  <span class="nx">applications</span>  <span class="p">=</span> <span class="p">[</span><span class="s2">"Spark"</span><span class="p">,</span> <span class="s2">"Hive"</span><span class="p">,</span> <span class="s2">"Presto"</span><span class="p">]</span>
  
  <span class="nx">ec2_attributes</span> <span class="p">{</span>
    <span class="nx">subnet_id</span>                         <span class="p">=</span> <span class="nx">var</span><span class="err">.</span><span class="nx">subnet_id</span>
    <span class="nx">emr_managed_master_security_group</span> <span class="p">=</span> <span class="nx">aws_security_group</span><span class="err">.</span><span class="nx">emr_master</span><span class="err">.</span><span class="nx">id</span>
    <span class="nx">emr_managed_slave_security_group</span>  <span class="p">=</span> <span class="nx">aws_security_group</span><span class="err">.</span><span class="nx">emr_slave</span><span class="err">.</span><span class="nx">id</span>
    <span class="nx">instance_profile</span>                  <span class="p">=</span> <span class="nx">aws_iam_instance_profile</span><span class="err">.</span><span class="nx">emr_profile</span><span class="err">.</span><span class="nx">arn</span>
  <span class="p">}</span>
  
  <span class="nx">master_instance_group</span> <span class="p">{</span>
    <span class="nx">instance_type</span> <span class="p">=</span> <span class="s2">"m5.xlarge"</span>
  <span class="p">}</span>
  
  <span class="nx">core_instance_group</span> <span class="p">{</span>
    <span class="nx">instance_type</span>  <span class="p">=</span> <span class="s2">"m5.xlarge"</span>
    <span class="nx">instance_count</span> <span class="p">=</span> <span class="mi">4</span>
  <span class="p">}</span>
  
  <span class="nx">configurations_json</span> <span class="p">=</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
    [
      {
        "Classification": "spark",
        "Properties": {
          "maximizeResourceAllocation": "true"
        }
      }
    ]
</span><span class="no">  EOF
</span><span class="p">}</span>
</pre></table></code></div></div><h3 id="5-managed-airflow-for-orchestration"><span class="mr-2">5. Managed Airflow for Orchestration</span><a href="#5-managed-airflow-for-orchestration" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Set up a fully managed Apache Airflow environment:</p><div class="language-hcl highlighter-rouge"><div class="code-header"> <span data-label-text="Hcl"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
</pre><td class="rouge-code"><pre><span class="nx">resource</span> <span class="s2">"aws_mwaa_environment"</span> <span class="s2">"data_orchestration"</span> <span class="p">{</span>
  <span class="nx">name</span>               <span class="p">=</span> <span class="s2">"data-pipeline-orchestrator"</span>
  <span class="nx">airflow_version</span>    <span class="p">=</span> <span class="s2">"2.5.1"</span>
  <span class="nx">source_bucket_arn</span>  <span class="p">=</span> <span class="nx">aws_s3_bucket</span><span class="err">.</span><span class="nx">airflow_assets</span><span class="err">.</span><span class="nx">arn</span>
  <span class="nx">dag_s3_path</span>        <span class="p">=</span> <span class="s2">"dags/"</span>
  
  <span class="nx">execution_role_arn</span> <span class="p">=</span> <span class="nx">aws_iam_role</span><span class="err">.</span><span class="nx">mwaa_execution</span><span class="err">.</span><span class="nx">arn</span>
  
  <span class="nx">network_configuration</span> <span class="p">{</span>
    <span class="nx">security_group_ids</span> <span class="p">=</span> <span class="p">[</span><span class="nx">aws_security_group</span><span class="err">.</span><span class="nx">mwaa_sg</span><span class="err">.</span><span class="nx">id</span><span class="p">]</span>
    <span class="nx">subnet_ids</span>         <span class="p">=</span> <span class="nx">var</span><span class="err">.</span><span class="nx">private_subnets</span>
  <span class="p">}</span>
  
  <span class="nx">logging_configuration</span> <span class="p">{</span>
    <span class="nx">dag_processing_logs</span> <span class="p">{</span>
      <span class="nx">enabled</span>   <span class="p">=</span> <span class="kc">true</span>
      <span class="nx">log_level</span> <span class="p">=</span> <span class="s2">"INFO"</span>
    <span class="p">}</span>
    <span class="nx">scheduler_logs</span> <span class="p">{</span>
      <span class="nx">enabled</span>   <span class="p">=</span> <span class="kc">true</span>
      <span class="nx">log_level</span> <span class="p">=</span> <span class="s2">"INFO"</span>
    <span class="p">}</span>
    <span class="nx">webserver_logs</span> <span class="p">{</span>
      <span class="nx">enabled</span>   <span class="p">=</span> <span class="kc">true</span>
      <span class="nx">log_level</span> <span class="p">=</span> <span class="s2">"INFO"</span>
    <span class="p">}</span>
    <span class="nx">worker_logs</span> <span class="p">{</span>
      <span class="nx">enabled</span>   <span class="p">=</span> <span class="kc">true</span>
      <span class="nx">log_level</span> <span class="p">=</span> <span class="s2">"INFO"</span>
    <span class="p">}</span>
  <span class="p">}</span>
  
  <span class="nx">environment_class</span> <span class="p">=</span> <span class="s2">"mw1.medium"</span>
  <span class="nx">min_workers</span>       <span class="p">=</span> <span class="mi">2</span>
  <span class="nx">max_workers</span>       <span class="p">=</span> <span class="mi">5</span>
<span class="p">}</span>
</pre></table></code></div></div><h2 id="practical-terraform-tips-for-data-engineers"><span class="mr-2">Practical Terraform Tips for Data Engineers</span><a href="#practical-terraform-tips-for-data-engineers" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h3 id="creating-reusable-data-infrastructure-modules"><span class="mr-2">Creating Reusable Data Infrastructure Modules</span><a href="#creating-reusable-data-infrastructure-modules" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>One of Terraformâ€™s most powerful features is modularity. You can create reusable modules for common data infrastructure patterns:</p><div class="language-hcl highlighter-rouge"><div class="code-header"> <span data-label-text="Hcl"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre><td class="rouge-code"><pre><span class="c1"># Example module usage</span>
<span class="nx">module</span> <span class="s2">"data_warehouse"</span> <span class="p">{</span>
  <span class="nx">source</span> <span class="p">=</span> <span class="s2">"./modules/redshift-warehouse"</span>
  
  <span class="nx">cluster_name</span> <span class="p">=</span> <span class="s2">"analytics-production"</span>
  <span class="nx">node_count</span>   <span class="p">=</span> <span class="mi">4</span>
  <span class="nx">node_type</span>    <span class="p">=</span> <span class="s2">"dc2.large"</span>
  <span class="nx">vpc_id</span>       <span class="p">=</span> <span class="nx">module</span><span class="err">.</span><span class="nx">vpc</span><span class="err">.</span><span class="nx">vpc_id</span>
  <span class="nx">subnet_ids</span>   <span class="p">=</span> <span class="nx">module</span><span class="err">.</span><span class="nx">vpc</span><span class="err">.</span><span class="nx">private_subnets</span>
<span class="p">}</span>

<span class="nx">module</span> <span class="s2">"data_lake"</span> <span class="p">{</span>
  <span class="nx">source</span> <span class="p">=</span> <span class="s2">"./modules/s3-data-lake"</span>
  
  <span class="nx">bucket_name</span>  <span class="p">=</span> <span class="s2">"company-data-lake-${var.environment}"</span>
  <span class="nx">enable_versioning</span> <span class="p">=</span> <span class="kc">true</span>
  <span class="nx">lifecycle_rules</span> <span class="p">=</span> <span class="nx">var</span><span class="err">.</span><span class="nx">storage_lifecycle_rules</span>
<span class="p">}</span>
</pre></table></code></div></div><h3 id="managing-secrets-for-data-connections"><span class="mr-2">Managing Secrets for Data Connections</span><a href="#managing-secrets-for-data-connections" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Handling credentials for databases, warehouses, and APIs is a common challenge. Terraform integrates with secrets management services:</p><div class="language-hcl highlighter-rouge"><div class="code-header"> <span data-label-text="Hcl"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre><td class="rouge-code"><pre><span class="c1"># Use AWS Secrets Manager for database credentials</span>
<span class="nx">resource</span> <span class="s2">"aws_secretsmanager_secret"</span> <span class="s2">"warehouse_creds"</span> <span class="p">{</span>
  <span class="nx">name</span> <span class="p">=</span> <span class="s2">"data/warehouse/admin"</span>
<span class="p">}</span>

<span class="nx">resource</span> <span class="s2">"aws_secretsmanager_secret_version"</span> <span class="s2">"warehouse_creds"</span> <span class="p">{</span>
  <span class="nx">secret_id</span>     <span class="p">=</span> <span class="nx">aws_secretsmanager_secret</span><span class="err">.</span><span class="nx">warehouse_creds</span><span class="err">.</span><span class="nx">id</span>
  <span class="nx">secret_string</span> <span class="p">=</span> <span class="nx">jsonencode</span><span class="err">(</span><span class="p">{</span>
    <span class="nx">username</span> <span class="p">=</span> <span class="nx">var</span><span class="err">.</span><span class="nx">admin_username</span>
    <span class="nx">password</span> <span class="p">=</span> <span class="nx">var</span><span class="err">.</span><span class="nx">admin_password</span>
  <span class="p">}</span><span class="err">)</span>
<span class="p">}</span>

<span class="c1"># Reference in your Redshift configuration</span>
<span class="nx">resource</span> <span class="s2">"aws_redshift_cluster"</span> <span class="s2">"warehouse"</span> <span class="p">{</span>
  <span class="c1"># ... other configuration</span>
  <span class="nx">master_username</span> <span class="p">=</span> <span class="nx">jsondecode</span><span class="err">(</span><span class="nx">data</span><span class="err">.</span><span class="nx">aws_secretsmanager_secret_version</span><span class="err">.</span><span class="nx">warehouse_creds</span><span class="err">.</span><span class="nx">secret_string</span><span class="err">)</span><span class="p">[</span><span class="s2">"username"</span><span class="p">]</span>
  <span class="nx">master_password</span> <span class="p">=</span> <span class="nx">jsondecode</span><span class="err">(</span><span class="nx">data</span><span class="err">.</span><span class="nx">aws_secretsmanager_secret_version</span><span class="err">.</span><span class="nx">warehouse_creds</span><span class="err">.</span><span class="nx">secret_string</span><span class="err">)</span><span class="p">[</span><span class="s2">"password"</span><span class="p">]</span>
<span class="p">}</span>
</pre></table></code></div></div><h3 id="testing-data-infrastructure-changes"><span class="mr-2">Testing Data Infrastructure Changes</span><a href="#testing-data-infrastructure-changes" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Before applying changes to production systems, you can validate them:</p><div class="language-bash highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre><span class="c"># Validate syntax and structure</span>
terraform validate

<span class="c"># Check formatting</span>
terraform <span class="nb">fmt</span> <span class="nt">-check</span>

<span class="c"># See what will change before applying</span>
terraform plan <span class="nt">-out</span><span class="o">=</span>changes.plan

<span class="c"># Apply the validated changes</span>
terraform apply changes.plan
</pre></table></code></div></div><h3 id="integration-with-cicd-for-data-projects"><span class="mr-2">Integration with CI/CD for Data Projects</span><a href="#integration-with-cicd-for-data-projects" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Integrate Terraform with your existing CI/CD pipelines to automate infrastructure updates alongside data pipeline code:</p><div class="language-yaml highlighter-rouge"><div class="code-header"> <span data-label-text="YAML"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
</pre><td class="rouge-code"><pre><span class="c1"># Example GitHub Actions workflow</span>
<span class="na">name</span><span class="pi">:</span> <span class="s">Deploy Data Infrastructure</span>

<span class="na">on</span><span class="pi">:</span>
  <span class="na">push</span><span class="pi">:</span>
    <span class="na">branches</span><span class="pi">:</span> <span class="pi">[</span><span class="nv">main</span><span class="pi">]</span>
    <span class="na">paths</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s1">'</span><span class="s">terraform/**'</span>
      <span class="pi">-</span> <span class="s1">'</span><span class="s">.github/workflows/terraform.yml'</span>

<span class="na">jobs</span><span class="pi">:</span>
  <span class="na">terraform</span><span class="pi">:</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/checkout@v3</span>
      
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Setup Terraform</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">hashicorp/setup-terraform@v2</span>
      
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Terraform Init</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">terraform init</span>
        <span class="na">working-directory</span><span class="pi">:</span> <span class="s">./terraform</span>
      
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Terraform Plan</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">terraform plan -out=tfplan</span>
        <span class="na">working-directory</span><span class="pi">:</span> <span class="s">./terraform</span>
      
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Terraform Apply</span>
        <span class="na">if</span><span class="pi">:</span> <span class="s">github.ref == 'refs/heads/main'</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">terraform apply -auto-approve tfplan</span>
        <span class="na">working-directory</span><span class="pi">:</span> <span class="s">./terraform</span>
</pre></table></code></div></div><h2 id="getting-started-as-a-data-engineer"><span class="mr-2">Getting Started as a Data Engineer</span><a href="#getting-started-as-a-data-engineer" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Ready to bring infrastructure as code to your data engineering practice? Hereâ€™s how to begin:</p><ol><li><strong>Start small</strong> - Automate a single component of your data platform first, like an S3 bucket or Redshift cluster<li><strong>Use existing modules</strong> - Explore the Terraform Registry for pre-built data infrastructure modules<li><strong>Adopt gradually</strong> - You donâ€™t need to migrate everything at once; Terraform can manage resources alongside manually created ones<li><strong>Version control</strong> - Store your Terraform files in the same repository as your data pipeline code<li><strong>Collaborate</strong> - Share your Terraform configurations with your team to build a consistent approach</ol><h2 id="conclusion"><span class="mr-2">Conclusion</span><a href="#conclusion" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>For data engineers, Terraform isnâ€™t just another tool â€“ itâ€™s a fundamental shift in how we work with infrastructure. By codifying our data platform, we eliminate manual errors, enable repeatable deployments, and build a foundation for continuous evolution.</p><p>Whether weâ€™re running data workloads on AWS, GCP, Azure, or across multiple clouds, Terraform provides a consistent interface to provision and manage the entire stack. This allows us to focus on what matters most: building robust data pipelines and extracting value from our organizationâ€™s data.</p><p>The initial investment in learning Terraform pays dividends in reduced complexity, greater reliability, and the ability to scale our data infrastructure alongside our growing data needs.</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/learning-journey/'>Learning Journey</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/terraform/" class="post-tag no-text-decoration" >terraform</a> <a href="/tags/devops/" class="post-tag no-text-decoration" >devops</a> <a href="/tags/hashicorp/" class="post-tag no-text-decoration" >hashicorp</a> <a href="/tags/iac/" class="post-tag no-text-decoration" >iac</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Terraform+for+Data+Engineers%3A+Automating+Your+Data+Infrastructure+-+samueltyh&url=https%3A%2F%2Fsamueltyh.github.io%2Fposts%2Fterraform-for-data-engineers-automating-your-data-infrastructure%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Terraform+for+Data+Engineers%3A+Automating+Your+Data+Infrastructure+-+samueltyh&u=https%3A%2F%2Fsamueltyh.github.io%2Fposts%2Fterraform-for-data-engineers-automating-your-data-infrastructure%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fsamueltyh.github.io%2Fposts%2Fterraform-for-data-engineers-automating-your-data-infrastructure%2F&text=Terraform+for+Data+Engineers%3A+Automating+Your+Data+Infrastructure+-+samueltyh" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/terraform-for-data-engineers-automating-your-data-infrastructure/">Terraform for Data Engineers: Automating Your Data Infrastructure</a><li><a href="/posts/how-to-train-a-customized-name-entities-recognition-ner-model-based-on-spacy-pre-trained-model/">How to train a customized Name Entities Recognition (NER) model based on spaCy pre-trained model</a><li><a href="/posts/run-your-own-apache-spark-jobs-in-aws-emr-and-s3/">Run your own Apache Spark jobs in AWS EMR and S3</a><li><a href="/posts/implementing-fivetran-data-source-connector-with-aws-lambda/">Implementing Fivetran Data Source Connector with AWS Lambda</a><li><a href="/posts/learning-and-takeaways-from-kubesimplify-workshop/">Learning and Takeaways from Kubesimplify Workshop</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/etl/">etl</a> <a class="post-tag" href="/tags/aws/">aws</a> <a class="post-tag" href="/tags/devops/">devops</a> <a class="post-tag" href="/tags/docker/">docker</a> <a class="post-tag" href="/tags/postgres/">postgres</a> <a class="post-tag" href="/tags/python/">python</a> <a class="post-tag" href="/tags/airflow/">airflow</a> <a class="post-tag" href="/tags/automation/">automation</a> <a class="post-tag" href="/tags/azure-data-studio/">azure-data-studio</a> <a class="post-tag" href="/tags/bash/">bash</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/learning-and-takeaways-from-kubesimplify-workshop/"><div class="card-body"> <em class="small" data-ts="1659823380" data-df="ll" > Aug 7, 2022 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Learning and Takeaways from Kubesimplify Workshop</h3><div class="text-muted small"><p> This post will keep the learning process and takeaways from the Kubesimplify workshops held by Saiyam Pathak. The motivation for me to catch up on this DevOps topic is to systematically learning by...</p></div></div></a></div><div class="card"> <a href="/posts/how-to-train-a-customized-name-entities-recognition-ner-model-based-on-spacy-pre-trained-model/"><div class="card-body"> <em class="small" data-ts="1583280000" data-df="ll" > Mar 4, 2020 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>How to train a customized Name Entities Recognition (NER) model based on spaCy pre-trained model</h3><div class="text-muted small"><p> How to train a customized Name Entities Recognition (NER) model based on spaCy pre-trained model There are a bunch of online resources to teach you how to train your own NER model by spaCy, so I w...</p></div></div></a></div><div class="card"> <a href="/posts/takeaway-unit-testing-of-bash-scripts/"><div class="card-body"> <em class="small" data-ts="1695901200" data-df="ll" > Sep 28, 2023 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Takeaway: Unit Testing of Bash Scripts</h3><div class="text-muted small"><p> Bash/Shell is a potent scripting language that lets us communicate with our computerâ€™s operating system. In many of my everyday tasks, I rely on Bash to carry out Linux commands and create certain ...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/building-a-production-ready-data-pipeline-with-airflow-and-dbt/" class="btn btn-outline-primary" prompt="Older"><p>Building a Production-Ready Data Pipeline with Airflow and dbt</p></a> <a href="/posts/free-n8n-hosting-leveraging-hugging-face-spaces-and-supabase-for-persistent-workflow-automation/" class="btn btn-outline-primary" prompt="Newer"><p>Free n8n Hosting: Leveraging Hugging Face Spaces and Supabase for Persistent Workflow Automation</p></a></div><div id="disqus_thread" class="pt-2 pb-2"><p class="text-center text-muted small"> Comments powered by <a href="https://disqus.com/">Disqus</a>.</p></div><script type="text/javascript"> var disqus_config = function () { this.page.url = 'https://samueltyh.github.io/posts/terraform-for-data-engineers-automating-your-data-infrastructure/'; this.page.identifier = '/posts/terraform-for-data-engineers-automating-your-data-infrastructure/'; }; /* Lazy loading */ var disqus_observer = new IntersectionObserver(function (entries) { if(entries[0].isIntersecting) { (function () { var d = document, s = d.createElement('script'); s.src = 'https://samuelTyh.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); disqus_observer.disconnect(); } }, { threshold: [0] }); disqus_observer.observe(document.querySelector('#disqus_thread')); /* Auto switch theme */ function reloadDisqus() { /* Disqus hasn't been loaded */ if (typeof DISQUS === "undefined") { return; } if (document.readyState == 'complete') { DISQUS.reset({ reload: true, config: disqus_config }); } } const modeToggle = document.querySelector(".mode-toggle"); if (typeof modeToggle !== "undefined") { /* modeToggle.addEventListener('click', reloadDisqus); // not pretty for 'color-scheme' */ window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', reloadDisqus); } </script></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> Â© 2025 <a href="https://twitter.com/samueltyh">Samuel Tseng</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/etl/">etl</a> <a class="post-tag" href="/tags/aws/">aws</a> <a class="post-tag" href="/tags/devops/">devops</a> <a class="post-tag" href="/tags/docker/">docker</a> <a class="post-tag" href="/tags/postgres/">postgres</a> <a class="post-tag" href="/tags/python/">python</a> <a class="post-tag" href="/tags/airflow/">airflow</a> <a class="post-tag" href="/tags/automation/">automation</a> <a class="post-tag" href="/tags/azure-data-studio/">azure-data-studio</a> <a class="post-tag" href="/tags/bash/">bash</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/de.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-7X84VGPKQ1"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-7X84VGPKQ1'); }); </script>
